# Project 03: 3D ìŠ¤ìºë„ˆ

[![ë‚œì´ë„](https://img.shields.io/badge/ë‚œì´ë„-â­â­â­â­â­_ì „ë¬¸ê°€-purple.svg)]()
[![ì˜ˆìƒì‹œê°„](https://img.shields.io/badge/ì˜ˆìƒì‹œê°„-15--20ì‹œê°„-blue.svg)]()
[![ì„ ìˆ˜ì§€ì‹](https://img.shields.io/badge/ì„ ìˆ˜ì§€ì‹-Module_04,_Open3D-orange.svg)]()

---

## ğŸ¯ í”„ë¡œì íŠ¸ ê°œìš”

| í•­ëª© | ë‚´ìš© |
|------|------|
| **ëª©í‘œ** | ìŠ¤í…Œë ˆì˜¤ ì¹´ë©”ë¼ë¡œ ë¬¼ì²´ë¥¼ ë‹¤ì–‘í•œ ê°ë„ì—ì„œ ìŠ¤ìº”í•˜ì—¬ 3D ëª¨ë¸ ìƒì„± |
| **ê¸°ëŠ¥** | ë‹¤ì¤‘ ì‹œì  ìº¡ì²˜, í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ì •í•©, ë©”ì‰¬ ìƒì„±, íŒŒì¼ ì¶œë ¥ |
| **ì¶œë ¥** | PLY, OBJ, STL íŒŒì¼ (3D í”„ë¦°íŒ… ê°€ëŠ¥) |

---

## ğŸ“‹ ëª©ì°¨

1. [í”„ë¡œì íŠ¸ êµ¬ì¡°](#1-í”„ë¡œì íŠ¸-êµ¬ì¡°)
2. [ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜](#2-ì‹œìŠ¤í…œ-ì•„í‚¤í…ì²˜)
3. [ë‹¤ì¤‘ ì‹œì  ìº¡ì²˜](#3-ë‹¤ì¤‘-ì‹œì -ìº¡ì²˜)
4. [í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ìƒì„±](#4-í¬ì¸íŠ¸-í´ë¼ìš°ë“œ-ìƒì„±)
5. [í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ì •í•©](#5-í¬ì¸íŠ¸-í´ë¼ìš°ë“œ-ì •í•©)
6. [í›„ì²˜ë¦¬ ë° í•„í„°ë§](#6-í›„ì²˜ë¦¬-ë°-í•„í„°ë§)
7. [ë©”ì‰¬ ìƒì„±](#7-ë©”ì‰¬-ìƒì„±)
8. [íŒŒì¼ ì¶œë ¥](#8-íŒŒì¼-ì¶œë ¥)
9. [GUI êµ¬í˜„](#9-gui-êµ¬í˜„)
10. [ì „ì²´ ì½”ë“œ](#10-ì „ì²´-ì½”ë“œ)

---

## 1. í”„ë¡œì íŠ¸ êµ¬ì¡°

```
Project_03_3D_Scanner/
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ stereo_params.yaml      # ìº˜ë¦¬ë¸Œë ˆì´ì…˜
â”‚   â””â”€â”€ scanner_config.yaml     # ìŠ¤ìºë„ˆ ì„¤ì •
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                 # ë©”ì¸ ì‹¤í–‰
â”‚   â”œâ”€â”€ stereo_camera.py        # ìŠ¤í…Œë ˆì˜¤ ì¹´ë©”ë¼
â”‚   â”œâ”€â”€ pointcloud_generator.py # í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ìƒì„±
â”‚   â”œâ”€â”€ cloud_registration.py   # í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ì •í•©
â”‚   â”œâ”€â”€ cloud_processor.py      # í›„ì²˜ë¦¬
â”‚   â”œâ”€â”€ mesh_generator.py       # ë©”ì‰¬ ìƒì„±
â”‚   â”œâ”€â”€ file_exporter.py        # íŒŒì¼ ì¶œë ¥
â”‚   â”œâ”€â”€ turntable_controller.py # í„´í…Œì´ë¸” ì œì–´ (ì˜µì…˜)
â”‚   â”œâ”€â”€ gui.py                  # GUI
â”‚   â””â”€â”€ utils.py                # ìœ í‹¸ë¦¬í‹°
â”œâ”€â”€ output/
â”‚   â”œâ”€â”€ pointclouds/            # í¬ì¸íŠ¸ í´ë¼ìš°ë“œ
â”‚   â”œâ”€â”€ meshes/                 # ë©”ì‰¬ íŒŒì¼
â”‚   â””â”€â”€ projects/               # í”„ë¡œì íŠ¸ ì €ì¥
â””â”€â”€ assets/
    â””â”€â”€ icons/                  # GUI ì•„ì´ì½˜
```

---

## 2. ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    3D ìŠ¤ìºë„ˆ ì›Œí¬í”Œë¡œìš°                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                  1. ë‹¤ì¤‘ ì‹œì  ìº¡ì²˜                     â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”   â”‚  â”‚
â”‚  â”‚  â”‚ 0Â°  â”‚   â”‚ 45Â° â”‚   â”‚ 90Â° â”‚   â”‚135Â° â”‚   â”‚180Â° â”‚...â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”¬â”€â”€â”˜   â””â”€â”€â”¬â”€â”€â”˜   â””â”€â”€â”¬â”€â”€â”˜   â””â”€â”€â”¬â”€â”€â”˜   â””â”€â”€â”¬â”€â”€â”˜   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚        â–¼        â–¼        â–¼        â–¼        â–¼            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚              2. ê°œë³„ í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ìƒì„±               â”‚  â”‚
â”‚  â”‚    â”Œâ”€â”€â”€â”    â”Œâ”€â”€â”€â”    â”Œâ”€â”€â”€â”    â”Œâ”€â”€â”€â”    â”Œâ”€â”€â”€â”       â”‚  â”‚
â”‚  â”‚    â”‚PC1â”‚    â”‚PC2â”‚    â”‚PC3â”‚    â”‚PC4â”‚    â”‚PC5â”‚ ...   â”‚  â”‚
â”‚  â”‚    â””â”€â”¬â”€â”˜    â””â”€â”¬â”€â”˜    â””â”€â”¬â”€â”˜    â””â”€â”¬â”€â”˜    â””â”€â”¬â”€â”˜       â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                           â–¼                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚              3. í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ì •í•© (ICP)             â”‚  â”‚
â”‚  â”‚                                                      â”‚  â”‚
â”‚  â”‚         PC1 â”€â”€â”                                      â”‚  â”‚
â”‚  â”‚         PC2 â”€â”€â”¼â”€â”€â†’ ì •í•©ëœ í¬ì¸íŠ¸ í´ë¼ìš°ë“œ              â”‚  â”‚
â”‚  â”‚         PC3 â”€â”€â”¤                                      â”‚  â”‚
â”‚  â”‚         ...   â”‚                                      â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                  â–¼                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚              4. í›„ì²˜ë¦¬                                â”‚  â”‚
â”‚  â”‚    ë…¸ì´ì¦ˆ ì œê±° â†’ ë‹¤ìš´ìƒ˜í”Œë§ â†’ ë²•ì„  ì¶”ì • â†’ ì •ë¦¬         â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                  â–¼                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚              5. ë©”ì‰¬ ìƒì„±                             â”‚  â”‚
â”‚  â”‚    Poisson Reconstruction / Ball Pivoting            â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                  â–¼                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚              6. íŒŒì¼ ì¶œë ¥                             â”‚  â”‚
â”‚  â”‚         PLY / OBJ / STL / GLTF                       â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 3. ë‹¤ì¤‘ ì‹œì  ìº¡ì²˜

### 3.1 ìŠ¤ìº” ì„¸ì…˜ ê´€ë¦¬

```python
"""
scan_session.py
ìŠ¤ìº” ì„¸ì…˜ ê´€ë¦¬
"""

import os
import json
import numpy as np
from datetime import datetime
from typing import List, Dict, Optional, Tuple
from dataclasses import dataclass, field, asdict
import cv2


@dataclass
class CaptureFrame:
    """ìº¡ì²˜ëœ í”„ë ˆì„"""
    frame_id: int
    angle: float                    # íšŒì „ ê°ë„ (ë„)
    timestamp: str                  # ìº¡ì²˜ ì‹œê°„
    left_image_path: str           # ì™¼ìª½ ì´ë¯¸ì§€ ê²½ë¡œ
    right_image_path: str          # ì˜¤ë¥¸ìª½ ì´ë¯¸ì§€ ê²½ë¡œ
    depth_path: Optional[str] = None        # ê¹Šì´ ë§µ ê²½ë¡œ
    pointcloud_path: Optional[str] = None   # í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ê²½ë¡œ
    transform: Optional[List] = None        # ë³€í™˜ í–‰ë ¬


@dataclass
class ScanSession:
    """ìŠ¤ìº” ì„¸ì…˜"""
    session_id: str
    name: str
    created_at: str
    num_captures: int = 0
    angle_step: float = 30.0        # ê°ë„ ê°„ê²©
    total_angles: int = 12          # ì´ ìº¡ì²˜ ìˆ˜ (360/30)
    captures: List[CaptureFrame] = field(default_factory=list)
    merged_cloud_path: Optional[str] = None
    mesh_path: Optional[str] = None
    status: str = "created"         # created, capturing, processing, completed


class ScanSessionManager:
    """ìŠ¤ìº” ì„¸ì…˜ ê´€ë¦¬ì"""
    
    def __init__(self, output_dir: str = "output/projects"):
        self.output_dir = output_dir
        self.current_session: Optional[ScanSession] = None
        
        os.makedirs(output_dir, exist_ok=True)
    
    def create_session(self, name: str, 
                       angle_step: float = 30.0) -> ScanSession:
        """ìƒˆ ìŠ¤ìº” ì„¸ì…˜ ìƒì„±"""
        
        session_id = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        session = ScanSession(
            session_id=session_id,
            name=name,
            created_at=datetime.now().isoformat(),
            angle_step=angle_step,
            total_angles=int(360 / angle_step)
        )
        
        # ì„¸ì…˜ ë””ë ‰í† ë¦¬ ìƒì„±
        session_dir = os.path.join(self.output_dir, session_id)
        os.makedirs(session_dir, exist_ok=True)
        os.makedirs(os.path.join(session_dir, "images"), exist_ok=True)
        os.makedirs(os.path.join(session_dir, "depth"), exist_ok=True)
        os.makedirs(os.path.join(session_dir, "pointclouds"), exist_ok=True)
        
        self.current_session = session
        self._save_session()
        
        print(f"âœ… ìƒˆ ìŠ¤ìº” ì„¸ì…˜ ìƒì„±: {session_id}")
        print(f"   ì´ë¦„: {name}")
        print(f"   ê°ë„ ê°„ê²©: {angle_step}Â°")
        print(f"   ì´ ìº¡ì²˜ ìˆ˜: {session.total_angles}")
        
        return session
    
    def load_session(self, session_id: str) -> Optional[ScanSession]:
        """ì„¸ì…˜ ë¡œë“œ"""
        
        session_file = os.path.join(self.output_dir, session_id, "session.json")
        
        if not os.path.exists(session_file):
            print(f"âŒ ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {session_id}")
            return None
        
        with open(session_file, 'r') as f:
            data = json.load(f)
        
        # CaptureFrame ë³µì›
        captures = [CaptureFrame(**c) for c in data.get('captures', [])]
        data['captures'] = captures
        
        session = ScanSession(**data)
        self.current_session = session
        
        print(f"âœ… ì„¸ì…˜ ë¡œë“œ: {session_id}")
        
        return session
    
    def _save_session(self):
        """í˜„ì¬ ì„¸ì…˜ ì €ì¥"""
        
        if self.current_session is None:
            return
        
        session_dir = os.path.join(self.output_dir, self.current_session.session_id)
        session_file = os.path.join(session_dir, "session.json")
        
        # dataclassë¥¼ dictë¡œ ë³€í™˜
        data = asdict(self.current_session)
        
        with open(session_file, 'w') as f:
            json.dump(data, f, indent=2)
    
    def add_capture(self, left_image: np.ndarray, 
                    right_image: np.ndarray,
                    angle: float) -> CaptureFrame:
        """ìº¡ì²˜ ì¶”ê°€"""
        
        if self.current_session is None:
            raise ValueError("í™œì„± ì„¸ì…˜ì´ ì—†ìŠµë‹ˆë‹¤.")
        
        session = self.current_session
        session_dir = os.path.join(self.output_dir, session.session_id)
        
        frame_id = session.num_captures
        timestamp = datetime.now().isoformat()
        
        # ì´ë¯¸ì§€ ì €ì¥
        left_path = os.path.join(session_dir, "images", f"left_{frame_id:03d}.png")
        right_path = os.path.join(session_dir, "images", f"right_{frame_id:03d}.png")
        
        cv2.imwrite(left_path, left_image)
        cv2.imwrite(right_path, right_image)
        
        # ìº¡ì²˜ í”„ë ˆì„ ìƒì„±
        capture = CaptureFrame(
            frame_id=frame_id,
            angle=angle,
            timestamp=timestamp,
            left_image_path=left_path,
            right_image_path=right_path
        )
        
        session.captures.append(capture)
        session.num_captures += 1
        session.status = "capturing"
        
        self._save_session()
        
        print(f"ğŸ“¸ ìº¡ì²˜ #{frame_id}: ê°ë„ {angle}Â°")
        
        return capture
    
    def get_session_dir(self) -> str:
        """í˜„ì¬ ì„¸ì…˜ ë””ë ‰í† ë¦¬ ë°˜í™˜"""
        if self.current_session:
            return os.path.join(self.output_dir, self.current_session.session_id)
        return ""
    
    def list_sessions(self) -> List[str]:
        """ëª¨ë“  ì„¸ì…˜ ëª©ë¡"""
        
        sessions = []
        
        for name in os.listdir(self.output_dir):
            session_file = os.path.join(self.output_dir, name, "session.json")
            if os.path.exists(session_file):
                sessions.append(name)
        
        return sorted(sessions, reverse=True)
```

### 3.2 ìˆ˜ë™/ìë™ ìº¡ì²˜

```python
"""
capture_controller.py
ìº¡ì²˜ ì œì–´
"""

import cv2
import numpy as np
import time
from typing import Optional, Callable
from enum import Enum


class CaptureMode(Enum):
    """ìº¡ì²˜ ëª¨ë“œ"""
    MANUAL = 1          # ìˆ˜ë™ (í‚¤ ì…ë ¥)
    TIMED = 2           # ì‹œê°„ ê¸°ë°˜ ìë™
    TURNTABLE = 3       # í„´í…Œì´ë¸” ì—°ë™


class CaptureController:
    """ìº¡ì²˜ ì œì–´ê¸°"""
    
    def __init__(self, stereo_camera, session_manager,
                 mode: CaptureMode = CaptureMode.MANUAL):
        """
        Parameters:
        - stereo_camera: StereoCamera ì¸ìŠ¤í„´ìŠ¤
        - session_manager: ScanSessionManager ì¸ìŠ¤í„´ìŠ¤
        - mode: ìº¡ì²˜ ëª¨ë“œ
        """
        
        self.camera = stereo_camera
        self.session_mgr = session_manager
        self.mode = mode
        
        # ìº¡ì²˜ ì„¤ì •
        self.angle_step = 30.0
        self.current_angle = 0.0
        
        # íƒ€ì´ë¨¸ ì„¤ì • (TIMED ëª¨ë“œ)
        self.capture_interval = 3.0  # ì´ˆ
        self.last_capture_time = 0
        
        # ì½œë°±
        self.on_capture: Optional[Callable] = None
        self.on_complete: Optional[Callable] = None
        
        # ìƒíƒœ
        self.is_capturing = False
        self.captures_remaining = 0
    
    def start_capture_sequence(self, angle_step: float = 30.0):
        """ìº¡ì²˜ ì‹œí€€ìŠ¤ ì‹œì‘"""
        
        self.angle_step = angle_step
        self.current_angle = 0.0
        self.captures_remaining = int(360 / angle_step)
        self.is_capturing = True
        
        print(f"\nğŸ¬ ìº¡ì²˜ ì‹œí€€ìŠ¤ ì‹œì‘")
        print(f"   ê°ë„ ê°„ê²©: {angle_step}Â°")
        print(f"   ì´ ìº¡ì²˜: {self.captures_remaining}")
        
        if self.mode == CaptureMode.MANUAL:
            print("   [SPACE] ìº¡ì²˜ | [ESC] ì·¨ì†Œ")
        elif self.mode == CaptureMode.TIMED:
            print(f"   {self.capture_interval}ì´ˆë§ˆë‹¤ ìë™ ìº¡ì²˜")
    
    def capture_single(self) -> bool:
        """ë‹¨ì¼ ìº¡ì²˜ ìˆ˜í–‰"""
        
        if self.captures_remaining <= 0:
            self._complete_sequence()
            return False
        
        # ì´ë¯¸ì§€ ìº¡ì²˜
        rect_left, rect_right = self.camera.capture_rectified()
        
        if rect_left is None or rect_right is None:
            print("âŒ ìº¡ì²˜ ì‹¤íŒ¨")
            return False
        
        # ì„¸ì…˜ì— ì¶”ê°€
        capture = self.session_mgr.add_capture(
            rect_left, rect_right, self.current_angle
        )
        
        # ì½œë°± í˜¸ì¶œ
        if self.on_capture:
            self.on_capture(capture)
        
        # ë‹¤ìŒ ê°ë„
        self.current_angle += self.angle_step
        self.captures_remaining -= 1
        
        if self.captures_remaining <= 0:
            self._complete_sequence()
        
        return True
    
    def update(self) -> bool:
        """ì—…ë°ì´íŠ¸ (ë©”ì¸ ë£¨í”„ì—ì„œ í˜¸ì¶œ)"""
        
        if not self.is_capturing:
            return False
        
        if self.mode == CaptureMode.TIMED:
            current_time = time.time()
            if current_time - self.last_capture_time >= self.capture_interval:
                self.last_capture_time = current_time
                return self.capture_single()
        
        return False
    
    def handle_key(self, key: int) -> bool:
        """í‚¤ ì…ë ¥ ì²˜ë¦¬"""
        
        if not self.is_capturing:
            return False
        
        if self.mode == CaptureMode.MANUAL:
            if key == ord(' '):  # ìŠ¤í˜ì´ìŠ¤ë°”
                return self.capture_single()
            elif key == 27:  # ESC
                self.cancel()
                return False
        
        return False
    
    def cancel(self):
        """ìº¡ì²˜ ì‹œí€€ìŠ¤ ì·¨ì†Œ"""
        self.is_capturing = False
        print("âŒ ìº¡ì²˜ ì‹œí€€ìŠ¤ ì·¨ì†Œë¨")
    
    def _complete_sequence(self):
        """ì‹œí€€ìŠ¤ ì™„ë£Œ"""
        
        self.is_capturing = False
        
        if self.session_mgr.current_session:
            self.session_mgr.current_session.status = "captured"
            self.session_mgr._save_session()
        
        print("âœ… ìº¡ì²˜ ì‹œí€€ìŠ¤ ì™„ë£Œ!")
        
        if self.on_complete:
            self.on_complete()
    
    def get_progress(self) -> Tuple[int, int, float]:
        """ì§„í–‰ ìƒí™© ë°˜í™˜"""
        
        if self.session_mgr.current_session:
            total = self.session_mgr.current_session.total_angles
            current = self.session_mgr.current_session.num_captures
            return current, total, self.current_angle
        
        return 0, 0, 0.0
```

---

## 4. í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ìƒì„±

### 4.1 ê¹Šì´ ë§µì—ì„œ í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ìƒì„±

```python
"""
pointcloud_generator.py
í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ìƒì„±
"""

import cv2
import numpy as np
import open3d as o3d
from typing import Tuple, Optional
import yaml


class PointCloudGenerator:
    """í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ìƒì„±ê¸°"""
    
    def __init__(self, calibration_file: str):
        """
        Parameters:
        - calibration_file: ìº˜ë¦¬ë¸Œë ˆì´ì…˜ íŒŒì¼ ê²½ë¡œ
        """
        
        self._load_calibration(calibration_file)
        self._setup_stereo_matcher()
    
    def _load_calibration(self, filename: str):
        """ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ë¡œë“œ"""
        
        with open(filename, 'r') as f:
            params = yaml.safe_load(f)
        
        self.img_size = tuple(params['image_size'])
        self.Q = np.array(params['Q'])
        self.P1 = np.array(params['P1'])
        self.baseline = params['baseline_mm']
        
        self.fx = self.P1[0, 0]
        self.fy = self.P1[1, 1]
        self.cx = self.P1[0, 2]
        self.cy = self.P1[1, 2]
        
        # ì •ë¥˜ ë§µ
        K1, D1 = np.array(params['K1']), np.array(params['D1'])
        K2, D2 = np.array(params['K2']), np.array(params['D2'])
        R1, R2 = np.array(params['R1']), np.array(params['R2'])
        P1, P2 = np.array(params['P1']), np.array(params['P2'])
        
        self.map1_left, self.map2_left = cv2.initUndistortRectifyMap(
            K1, D1, R1, P1, self.img_size, cv2.CV_32FC1)
        self.map1_right, self.map2_right = cv2.initUndistortRectifyMap(
            K2, D2, R2, P2, self.img_size, cv2.CV_32FC1)
    
    def _setup_stereo_matcher(self):
        """ìŠ¤í…Œë ˆì˜¤ ë§¤ì²˜ ì„¤ì •"""
        
        self.stereo = cv2.StereoSGBM_create(
            minDisparity=0,
            numDisparities=128,
            blockSize=5,
            P1=8 * 3 * 5 ** 2,
            P2=32 * 3 * 5 ** 2,
            disp12MaxDiff=1,
            uniquenessRatio=10,
            speckleWindowSize=100,
            speckleRange=2,
            mode=cv2.STEREO_SGBM_MODE_SGBM_3WAY
        )
        
        # WLS í•„í„°
        self.right_matcher = cv2.ximgproc.createRightMatcher(self.stereo)
        self.wls_filter = cv2.ximgproc.createDisparityWLSFilter(self.stereo)
        self.wls_filter.setLambda(8000)
        self.wls_filter.setSigmaColor(1.5)
    
    def rectify_images(self, left: np.ndarray, 
                       right: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        """ì´ë¯¸ì§€ ì •ë¥˜"""
        
        rect_left = cv2.remap(left, self.map1_left, self.map2_left, 
                              cv2.INTER_LINEAR)
        rect_right = cv2.remap(right, self.map1_right, self.map2_right,
                               cv2.INTER_LINEAR)
        
        return rect_left, rect_right
    
    def compute_disparity(self, rect_left: np.ndarray,
                          rect_right: np.ndarray) -> np.ndarray:
        """ì‹œì°¨ ë§µ ê³„ì‚°"""
        
        # ì™¼ìª½/ì˜¤ë¥¸ìª½ ì‹œì°¨
        disp_left = self.stereo.compute(rect_left, rect_right)
        disp_right = self.right_matcher.compute(rect_right, rect_left)
        
        # WLS í•„í„°
        disparity = self.wls_filter.filter(
            disp_left, rect_left, 
            disparity_map_right=disp_right
        )
        
        disparity = disparity.astype(np.float32) / 16.0
        
        return disparity
    
    def disparity_to_pointcloud(self, disparity: np.ndarray,
                                 color_image: np.ndarray,
                                 min_depth: float = 100,
                                 max_depth: float = 2000) -> o3d.geometry.PointCloud:
        """
        ì‹œì°¨ ë§µì„ í¬ì¸íŠ¸ í´ë¼ìš°ë“œë¡œ ë³€í™˜
        
        Parameters:
        - disparity: ì‹œì°¨ ë§µ
        - color_image: ì»¬ëŸ¬ ì´ë¯¸ì§€ (BGR)
        - min_depth, max_depth: ê¹Šì´ ë²”ìœ„ (mm)
        
        Returns:
        - pcd: Open3D PointCloud
        """
        
        # 3D ì¬íˆ¬ì˜
        points_3d = cv2.reprojectImageTo3D(disparity, self.Q)
        
        h, w = disparity.shape
        
        # ìœ íš¨í•œ ì  ë§ˆìŠ¤í¬
        z = points_3d[:, :, 2]
        mask = (disparity > 0) & (z > min_depth) & (z < max_depth)
        
        # í¬ì¸íŠ¸ ì¶”ì¶œ
        points = points_3d[mask]
        
        # ìƒ‰ìƒ ì¶”ì¶œ (BGR â†’ RGB, ì •ê·œí™”)
        colors = color_image[mask][:, ::-1] / 255.0
        
        # Open3D í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ìƒì„±
        pcd = o3d.geometry.PointCloud()
        pcd.points = o3d.utility.Vector3dVector(points)
        pcd.colors = o3d.utility.Vector3dVector(colors)
        
        return pcd
    
    def generate_from_stereo_pair(self, left_image: np.ndarray,
                                   right_image: np.ndarray,
                                   min_depth: float = 100,
                                   max_depth: float = 2000) -> Tuple[o3d.geometry.PointCloud, np.ndarray]:
        """
        ìŠ¤í…Œë ˆì˜¤ ì´ë¯¸ì§€ ìŒì—ì„œ í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ìƒì„±
        
        Returns:
        - pcd: í¬ì¸íŠ¸ í´ë¼ìš°ë“œ
        - disparity: ì‹œì°¨ ë§µ
        """
        
        # ì •ë¥˜
        rect_left, rect_right = self.rectify_images(left_image, right_image)
        
        # ì‹œì°¨ ê³„ì‚°
        disparity = self.compute_disparity(rect_left, rect_right)
        
        # í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ìƒì„±
        pcd = self.disparity_to_pointcloud(disparity, rect_left, 
                                           min_depth, max_depth)
        
        return pcd, disparity
    
    def generate_from_files(self, left_path: str, right_path: str,
                            min_depth: float = 100,
                            max_depth: float = 2000) -> o3d.geometry.PointCloud:
        """íŒŒì¼ì—ì„œ í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ìƒì„±"""
        
        left = cv2.imread(left_path)
        right = cv2.imread(right_path)
        
        if left is None or right is None:
            raise ValueError(f"ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {left_path}, {right_path}")
        
        pcd, _ = self.generate_from_stereo_pair(left, right, min_depth, max_depth)
        
        return pcd
```

### 4.2 ë°°ê²½ ì œê±°

```python
"""
background_removal.py
ë°°ê²½ ì œê±° ìœ í‹¸ë¦¬í‹°
"""

import cv2
import numpy as np
import open3d as o3d
from typing import Tuple, Optional


class BackgroundRemover:
    """ë°°ê²½ ì œê±°"""
    
    def __init__(self):
        # ë°°ê²½ ë¹¼ê¸° ì•Œê³ ë¦¬ì¦˜
        self.bg_subtractor = cv2.createBackgroundSubtractorMOG2(
            history=100,
            varThreshold=50,
            detectShadows=False
        )
        
        # í•™ìŠµëœ ë°°ê²½ (ì°¸ì¡°ìš©)
        self.background_depth: Optional[np.ndarray] = None
    
    def learn_background(self, depth: np.ndarray, num_frames: int = 30):
        """ë°°ê²½ í•™ìŠµ (ë¬¼ì²´ ì—†ì´)"""
        
        # ì—¬ëŸ¬ í”„ë ˆì„ í‰ê· 
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ë°˜ë³µ ìº¡ì²˜ í•„ìš”
        self.background_depth = depth.copy()
        print("âœ… ë°°ê²½ í•™ìŠµ ì™„ë£Œ")
    
    def remove_by_depth_difference(self, depth: np.ndarray,
                                    threshold: float = 50) -> np.ndarray:
        """
        ê¹Šì´ ì°¨ì´ë¡œ ë°°ê²½ ì œê±°
        
        Returns:
        - mask: ì „ê²½ ë§ˆìŠ¤í¬
        """
        
        if self.background_depth is None:
            return np.ones(depth.shape, dtype=bool)
        
        diff = np.abs(depth - self.background_depth)
        
        # ë¬¼ì²´ ì˜ì—­: ë°°ê²½ë³´ë‹¤ ê°€ê¹Œì›€ (ì‹œì°¨ê°€ í¼, ê¹Šì´ê°€ ì‘ìŒ)
        foreground = (self.background_depth - depth) > threshold
        
        return foreground
    
    def remove_by_distance(self, depth: np.ndarray,
                           min_dist: float = 200,
                           max_dist: float = 1000) -> np.ndarray:
        """
        ê±°ë¦¬ ë²”ìœ„ë¡œ ë°°ê²½ ì œê±°
        
        Returns:
        - mask: ê±°ë¦¬ ë²”ìœ„ ë‚´ ë§ˆìŠ¤í¬
        """
        
        mask = (depth > min_dist) & (depth < max_dist)
        
        return mask
    
    def remove_by_color(self, image: np.ndarray,
                        bg_color: Tuple[int, int, int],
                        threshold: int = 30) -> np.ndarray:
        """
        ìƒ‰ìƒìœ¼ë¡œ ë°°ê²½ ì œê±° (ê·¸ë¦°ìŠ¤í¬ë¦° ë“±)
        
        Parameters:
        - image: BGR ì´ë¯¸ì§€
        - bg_color: ë°°ê²½ ìƒ‰ìƒ (B, G, R)
        - threshold: ìƒ‰ìƒ ì„ê³„ê°’
        
        Returns:
        - mask: ì „ê²½ ë§ˆìŠ¤í¬
        """
        
        diff = np.abs(image.astype(np.int16) - np.array(bg_color))
        distance = np.sqrt(np.sum(diff ** 2, axis=2))
        
        mask = distance > threshold
        
        return mask
    
    def apply_mask_to_pointcloud(self, pcd: o3d.geometry.PointCloud,
                                  mask: np.ndarray,
                                  image_shape: Tuple[int, int]) -> o3d.geometry.PointCloud:
        """
        2D ë§ˆìŠ¤í¬ë¥¼ 3D í¬ì¸íŠ¸ í´ë¼ìš°ë“œì— ì ìš©
        
        ì°¸ê³ : ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” í”½ì…€-í¬ì¸íŠ¸ ë§¤í•‘ í•„ìš”
        """
        
        # ê°„ë‹¨í•œ êµ¬í˜„: í¬ì¸íŠ¸ ê°œìˆ˜ ê¸°ë°˜ í•„í„°ë§
        # ì‹¤ì œë¡œëŠ” ì—­íˆ¬ì˜ í•„ìš”
        
        return pcd
    
    def remove_plane(self, pcd: o3d.geometry.PointCloud,
                     distance_threshold: float = 10) -> o3d.geometry.PointCloud:
        """
        í‰ë©´ ì œê±° (í…Œì´ë¸” ë“±)
        
        RANSACìœ¼ë¡œ í‰ë©´ ê²€ì¶œ í›„ ì œê±°
        """
        
        # RANSAC í‰ë©´ ê²€ì¶œ
        plane_model, inliers = pcd.segment_plane(
            distance_threshold=distance_threshold,
            ransac_n=3,
            num_iterations=1000
        )
        
        # í‰ë©´ì´ ì•„ë‹Œ í¬ì¸íŠ¸ë§Œ ì¶”ì¶œ
        outlier_cloud = pcd.select_by_index(inliers, invert=True)
        
        print(f"âœ… í‰ë©´ ì œê±°: {len(inliers)} points removed")
        
        return outlier_cloud
```

---

## 5. í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ì •í•©

### 5.1 ICP ê¸°ë°˜ ì •í•©

```python
"""
cloud_registration.py
í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ì •í•©
"""

import numpy as np
import open3d as o3d
from typing import List, Tuple, Optional
import copy


class PointCloudRegistration:
    """í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ì •í•©"""
    
    def __init__(self, voxel_size: float = 5.0):
        """
        Parameters:
        - voxel_size: ë‹¤ìš´ìƒ˜í”Œë§ ë³µì…€ í¬ê¸° (mm)
        """
        
        self.voxel_size = voxel_size
    
    def preprocess(self, pcd: o3d.geometry.PointCloud) -> Tuple[o3d.geometry.PointCloud, o3d.pipelines.registration.Feature]:
        """
        ì •í•©ì„ ìœ„í•œ ì „ì²˜ë¦¬
        
        Returns:
        - pcd_down: ë‹¤ìš´ìƒ˜í”Œë§ëœ í¬ì¸íŠ¸ í´ë¼ìš°ë“œ
        - fpfh: FPFH íŠ¹ì§•
        """
        
        # ë‹¤ìš´ìƒ˜í”Œë§
        pcd_down = pcd.voxel_down_sample(self.voxel_size)
        
        # ë²•ì„  ì¶”ì •
        pcd_down.estimate_normals(
            search_param=o3d.geometry.KDTreeSearchParamHybrid(
                radius=self.voxel_size * 2,
                max_nn=30
            )
        )
        
        # FPFH íŠ¹ì§• ê³„ì‚°
        fpfh = o3d.pipelines.registration.compute_fpfh_feature(
            pcd_down,
            o3d.geometry.KDTreeSearchParamHybrid(
                radius=self.voxel_size * 5,
                max_nn=100
            )
        )
        
        return pcd_down, fpfh
    
    def global_registration(self, source: o3d.geometry.PointCloud,
                            target: o3d.geometry.PointCloud) -> np.ndarray:
        """
        ê¸€ë¡œë²Œ ì •í•© (RANSAC ê¸°ë°˜)
        
        ì´ˆê¸° ì •ë ¬ì„ ìœ„í•œ ê±°ì¹œ ì •í•©
        
        Returns:
        - transformation: 4x4 ë³€í™˜ í–‰ë ¬
        """
        
        # ì „ì²˜ë¦¬
        source_down, source_fpfh = self.preprocess(source)
        target_down, target_fpfh = self.preprocess(target)
        
        # RANSAC ì •í•©
        distance_threshold = self.voxel_size * 1.5
        
        result = o3d.pipelines.registration.registration_ransac_based_on_feature_matching(
            source_down, target_down,
            source_fpfh, target_fpfh,
            mutual_filter=True,
            max_correspondence_distance=distance_threshold,
            estimation_method=o3d.pipelines.registration.TransformationEstimationPointToPoint(False),
            ransac_n=4,
            checkers=[
                o3d.pipelines.registration.CorrespondenceCheckerBasedOnEdgeLength(0.9),
                o3d.pipelines.registration.CorrespondenceCheckerBasedOnDistance(distance_threshold)
            ],
            criteria=o3d.pipelines.registration.RANSACConvergenceCriteria(4000000, 500)
        )
        
        print(f"ê¸€ë¡œë²Œ ì •í•© fitness: {result.fitness:.4f}")
        
        return result.transformation
    
    def icp_registration(self, source: o3d.geometry.PointCloud,
                         target: o3d.geometry.PointCloud,
                         init_transform: np.ndarray = np.eye(4),
                         max_iteration: int = 100) -> Tuple[np.ndarray, float]:
        """
        ICP (Iterative Closest Point) ì •í•©
        
        Returns:
        - transformation: 4x4 ë³€í™˜ í–‰ë ¬
        - fitness: ì •í•© í’ˆì§ˆ (0-1)
        """
        
        threshold = self.voxel_size * 0.5
        
        # Point-to-Plane ICP
        source.estimate_normals(
            search_param=o3d.geometry.KDTreeSearchParamHybrid(
                radius=self.voxel_size * 2, max_nn=30
            )
        )
        target.estimate_normals(
            search_param=o3d.geometry.KDTreeSearchParamHybrid(
                radius=self.voxel_size * 2, max_nn=30
            )
        )
        
        result = o3d.pipelines.registration.registration_icp(
            source, target,
            threshold,
            init_transform,
            o3d.pipelines.registration.TransformationEstimationPointToPlane(),
            o3d.pipelines.registration.ICPConvergenceCriteria(
                max_iteration=max_iteration
            )
        )
        
        print(f"ICP ì •í•© fitness: {result.fitness:.4f}, RMSE: {result.inlier_rmse:.4f}")
        
        return result.transformation, result.fitness
    
    def colored_icp(self, source: o3d.geometry.PointCloud,
                    target: o3d.geometry.PointCloud,
                    init_transform: np.ndarray = np.eye(4)) -> Tuple[np.ndarray, float]:
        """
        ìƒ‰ìƒ ì •ë³´ë¥¼ í™œìš©í•œ ICP
        
        í…ìŠ¤ì²˜ê°€ ìˆëŠ” ë¬¼ì²´ì— íš¨ê³¼ì 
        """
        
        # ë²•ì„  ì¶”ì •
        for pcd in [source, target]:
            pcd.estimate_normals(
                search_param=o3d.geometry.KDTreeSearchParamHybrid(
                    radius=self.voxel_size * 2, max_nn=30
                )
            )
        
        result = o3d.pipelines.registration.registration_colored_icp(
            source, target,
            self.voxel_size,
            init_transform,
            o3d.pipelines.registration.TransformationEstimationForColoredICP(),
            o3d.pipelines.registration.ICPConvergenceCriteria(
                relative_fitness=1e-6,
                relative_rmse=1e-6,
                max_iteration=50
            )
        )
        
        print(f"Colored ICP fitness: {result.fitness:.4f}")
        
        return result.transformation, result.fitness
    
    def register_with_known_rotation(self, source: o3d.geometry.PointCloud,
                                      target: o3d.geometry.PointCloud,
                                      angle_deg: float) -> np.ndarray:
        """
        ì•Œë ¤ì§„ íšŒì „ ê°ë„ë¡œ ì´ˆê¸°í™” í›„ ICP
        
        í„´í…Œì´ë¸” ì‚¬ìš© ì‹œ í™œìš©
        
        Parameters:
        - angle_deg: Yì¶• ê¸°ì¤€ íšŒì „ ê°ë„ (ë„)
        """
        
        # íšŒì „ í–‰ë ¬ ìƒì„± (Yì¶• ê¸°ì¤€)
        angle_rad = np.radians(angle_deg)
        R = np.array([
            [np.cos(angle_rad), 0, np.sin(angle_rad)],
            [0, 1, 0],
            [-np.sin(angle_rad), 0, np.cos(angle_rad)]
        ])
        
        init_transform = np.eye(4)
        init_transform[:3, :3] = R
        
        # ICP ì •ë°€ ì •í•©
        transform, fitness = self.icp_registration(
            source, target, init_transform
        )
        
        return transform


class MultiViewRegistration:
    """ë‹¤ì¤‘ ì‹œì  ì •í•©"""
    
    def __init__(self, voxel_size: float = 5.0):
        self.registration = PointCloudRegistration(voxel_size)
        self.voxel_size = voxel_size
    
    def register_sequential(self, pointclouds: List[o3d.geometry.PointCloud],
                            angles: List[float] = None) -> o3d.geometry.PointCloud:
        """
        ìˆœì°¨ì  ì •í•©
        
        Parameters:
        - pointclouds: í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ë¦¬ìŠ¤íŠ¸
        - angles: ê° í¬ì¸íŠ¸ í´ë¼ìš°ë“œì˜ íšŒì „ ê°ë„ (ì˜µì…˜)
        
        Returns:
        - merged: ë³‘í•©ëœ í¬ì¸íŠ¸ í´ë¼ìš°ë“œ
        """
        
        if len(pointclouds) == 0:
            return o3d.geometry.PointCloud()
        
        if len(pointclouds) == 1:
            return pointclouds[0]
        
        print(f"\nğŸ”„ {len(pointclouds)}ê°œ í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ì •í•© ì‹œì‘")
        
        # ì²« ë²ˆì§¸ë¥¼ ê¸°ì¤€ìœ¼ë¡œ
        merged = copy.deepcopy(pointclouds[0])
        transforms = [np.eye(4)]
        
        for i in range(1, len(pointclouds)):
            print(f"\n[{i}/{len(pointclouds)-1}] ì •í•© ì¤‘...")
            
            source = pointclouds[i]
            
            # ì´ˆê¸° ë³€í™˜ (ì•Œë ¤ì§„ ê°ë„ ì‚¬ìš©)
            if angles and len(angles) > i:
                angle_diff = angles[i] - angles[0]
                init_transform = self._rotation_matrix_y(angle_diff)
            else:
                # ê¸€ë¡œë²Œ ì •í•©ìœ¼ë¡œ ì´ˆê¸°í™”
                init_transform = self.registration.global_registration(source, merged)
            
            # ICP ì •ë°€ ì •í•©
            transform, fitness = self.registration.colored_icp(
                source, merged, init_transform
            )
            
            transforms.append(transform)
            
            # ë³€í™˜ ì ìš© ë° ë³‘í•©
            source_transformed = copy.deepcopy(source)
            source_transformed.transform(transform)
            merged += source_transformed
            
            # ì¤‘ê°„ ë‹¤ìš´ìƒ˜í”Œë§ (ë©”ëª¨ë¦¬ ê´€ë¦¬)
            if len(merged.points) > 1000000:
                merged = merged.voxel_down_sample(self.voxel_size)
        
        print(f"\nâœ… ì •í•© ì™„ë£Œ: {len(merged.points):,} points")
        
        return merged
    
    def register_global_optimization(self, pointclouds: List[o3d.geometry.PointCloud]) -> o3d.geometry.PointCloud:
        """
        ê¸€ë¡œë²Œ ìµœì í™” ê¸°ë°˜ ì •í•©
        
        ëª¨ë“  ìŒ ê°„ì˜ ê´€ê³„ë¥¼ ê³ ë ¤í•œ ìµœì í™”
        """
        
        n = len(pointclouds)
        
        if n == 0:
            return o3d.geometry.PointCloud()
        
        print(f"\nğŸ”„ ê¸€ë¡œë²Œ ìµœì í™” ì •í•© ({n}ê°œ)")
        
        # í¬ì¦ˆ ê·¸ë˜í”„ ìƒì„±
        pose_graph = o3d.pipelines.registration.PoseGraph()
        
        # ë…¸ë“œ ì¶”ê°€
        for i in range(n):
            pose_graph.nodes.append(
                o3d.pipelines.registration.PoseGraphNode(np.eye(4))
            )
        
        # ì—£ì§€ ì¶”ê°€ (ì¸ì ‘ ìŒ)
        for i in range(n):
            j = (i + 1) % n
            
            source = pointclouds[i]
            target = pointclouds[j]
            
            # ì •í•©
            init_transform = self.registration.global_registration(source, target)
            transform, _ = self.registration.icp_registration(
                source, target, init_transform
            )
            
            # ì—£ì§€ ì¶”ê°€
            pose_graph.edges.append(
                o3d.pipelines.registration.PoseGraphEdge(
                    i, j, transform,
                    np.eye(6),  # ì •ë³´ í–‰ë ¬
                    uncertain=False
                )
            )
        
        # ê¸€ë¡œë²Œ ìµœì í™”
        option = o3d.pipelines.registration.GlobalOptimizationOption(
            max_correspondence_distance=self.voxel_size * 1.5,
            edge_prune_threshold=0.25,
            preference_loop_closure=1.0
        )
        
        o3d.pipelines.registration.global_optimization(
            pose_graph,
            o3d.pipelines.registration.GlobalOptimizationLevenbergMarquardt(),
            o3d.pipelines.registration.GlobalOptimizationConvergenceCriteria(),
            option
        )
        
        # ë³€í™˜ ì ìš© ë° ë³‘í•©
        merged = o3d.geometry.PointCloud()
        
        for i, pcd in enumerate(pointclouds):
            pcd_transformed = copy.deepcopy(pcd)
            pcd_transformed.transform(pose_graph.nodes[i].pose)
            merged += pcd_transformed
        
        print(f"âœ… ê¸€ë¡œë²Œ ìµœì í™” ì™„ë£Œ: {len(merged.points):,} points")
        
        return merged
    
    def _rotation_matrix_y(self, angle_deg: float) -> np.ndarray:
        """Yì¶• íšŒì „ í–‰ë ¬"""
        angle_rad = np.radians(angle_deg)
        R = np.array([
            [np.cos(angle_rad), 0, np.sin(angle_rad), 0],
            [0, 1, 0, 0],
            [-np.sin(angle_rad), 0, np.cos(angle_rad), 0],
            [0, 0, 0, 1]
        ])
        return R
```

---

## 6. í›„ì²˜ë¦¬ ë° í•„í„°ë§

### 6.1 í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ì²˜ë¦¬

```python
"""
cloud_processor.py
í¬ì¸íŠ¸ í´ë¼ìš°ë“œ í›„ì²˜ë¦¬
"""

import numpy as np
import open3d as o3d
from typing import Tuple, Optional


class PointCloudProcessor:
    """í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ì²˜ë¦¬ê¸°"""
    
    def __init__(self):
        pass
    
    def filter_statistical_outlier(self, pcd: o3d.geometry.PointCloud,
                                    nb_neighbors: int = 20,
                                    std_ratio: float = 2.0) -> o3d.geometry.PointCloud:
        """
        í†µê³„ì  ì´ìƒì¹˜ ì œê±°
        """
        
        original_count = len(pcd.points)
        
        filtered, _ = pcd.remove_statistical_outlier(
            nb_neighbors=nb_neighbors,
            std_ratio=std_ratio
        )
        
        removed = original_count - len(filtered.points)
        print(f"í†µê³„ì  ì´ìƒì¹˜ ì œê±°: {removed:,} points ({removed/original_count*100:.1f}%)")
        
        return filtered
    
    def filter_radius_outlier(self, pcd: o3d.geometry.PointCloud,
                              nb_points: int = 16,
                              radius: float = 10.0) -> o3d.geometry.PointCloud:
        """
        ë°˜ê²½ ê¸°ë°˜ ì´ìƒì¹˜ ì œê±°
        """
        
        original_count = len(pcd.points)
        
        filtered, _ = pcd.remove_radius_outlier(
            nb_points=nb_points,
            radius=radius
        )
        
        removed = original_count - len(filtered.points)
        print(f"ë°˜ê²½ ì´ìƒì¹˜ ì œê±°: {removed:,} points")
        
        return filtered
    
    def downsample(self, pcd: o3d.geometry.PointCloud,
                   voxel_size: float = 2.0) -> o3d.geometry.PointCloud:
        """
        ë³µì…€ ë‹¤ìš´ìƒ˜í”Œë§
        """
        
        original_count = len(pcd.points)
        
        downsampled = pcd.voxel_down_sample(voxel_size)
        
        new_count = len(downsampled.points)
        print(f"ë‹¤ìš´ìƒ˜í”Œë§: {original_count:,} â†’ {new_count:,} points")
        
        return downsampled
    
    def estimate_normals(self, pcd: o3d.geometry.PointCloud,
                         radius: float = 10.0,
                         max_nn: int = 30) -> o3d.geometry.PointCloud:
        """
        ë²•ì„  ì¶”ì •
        """
        
        pcd.estimate_normals(
            search_param=o3d.geometry.KDTreeSearchParamHybrid(
                radius=radius,
                max_nn=max_nn
            )
        )
        
        # ì¼ê´€ëœ ë°©í–¥ìœ¼ë¡œ ì¡°ì •
        pcd.orient_normals_consistent_tangent_plane(k=15)
        
        print(f"ë²•ì„  ì¶”ì • ì™„ë£Œ: {len(pcd.normals)} normals")
        
        return pcd
    
    def smooth(self, pcd: o3d.geometry.PointCloud,
               iterations: int = 1) -> o3d.geometry.PointCloud:
        """
        í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ìŠ¤ë¬´ë”© (í‰ê·  í•„í„°)
        
        ì£¼ì˜: Open3D ê¸°ë³¸ ì œê³µ ì•„ë‹˜, ê°„ë‹¨í•œ êµ¬í˜„
        """
        
        points = np.asarray(pcd.points)
        colors = np.asarray(pcd.colors) if pcd.has_colors() else None
        
        # KD-Tree ìƒì„±
        kdtree = o3d.geometry.KDTreeFlann(pcd)
        
        new_points = np.zeros_like(points)
        
        for i in range(len(points)):
            # ì´ì›ƒ ì°¾ê¸°
            [k, idx, _] = kdtree.search_knn_vector_3d(points[i], 10)
            
            # í‰ê·  ìœ„ì¹˜
            new_points[i] = np.mean(points[idx], axis=0)
        
        smoothed = o3d.geometry.PointCloud()
        smoothed.points = o3d.utility.Vector3dVector(new_points)
        
        if colors is not None:
            smoothed.colors = o3d.utility.Vector3dVector(colors)
        
        print(f"ìŠ¤ë¬´ë”© ì™„ë£Œ ({iterations} iterations)")
        
        return smoothed
    
    def crop_by_bbox(self, pcd: o3d.geometry.PointCloud,
                     min_bound: np.ndarray,
                     max_bound: np.ndarray) -> o3d.geometry.PointCloud:
        """
        ë°”ìš´ë”© ë°•ìŠ¤ë¡œ í¬ë¡­
        """
        
        bbox = o3d.geometry.AxisAlignedBoundingBox(
            min_bound=min_bound,
            max_bound=max_bound
        )
        
        cropped = pcd.crop(bbox)
        
        print(f"í¬ë¡­: {len(pcd.points):,} â†’ {len(cropped.points):,} points")
        
        return cropped
    
    def process_pipeline(self, pcd: o3d.geometry.PointCloud,
                         voxel_size: float = 2.0,
                         remove_outliers: bool = True) -> o3d.geometry.PointCloud:
        """
        í‘œì¤€ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
        """
        
        print("\nğŸ”§ í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸")
        print("="*40)
        
        # 1. ë‹¤ìš´ìƒ˜í”Œë§
        pcd = self.downsample(pcd, voxel_size)
        
        # 2. ì´ìƒì¹˜ ì œê±°
        if remove_outliers:
            pcd = self.filter_statistical_outlier(pcd)
        
        # 3. ë²•ì„  ì¶”ì •
        pcd = self.estimate_normals(pcd, radius=voxel_size * 3)
        
        print("="*40)
        print(f"âœ… ì²˜ë¦¬ ì™„ë£Œ: {len(pcd.points):,} points")
        
        return pcd
```

---

## 7. ë©”ì‰¬ ìƒì„±

### 7.1 í‘œë©´ ì¬êµ¬ì„±

```python
"""
mesh_generator.py
ë©”ì‰¬ ìƒì„±
"""

import numpy as np
import open3d as o3d
from typing import Optional, Tuple


class MeshGenerator:
    """ë©”ì‰¬ ìƒì„±ê¸°"""
    
    def __init__(self):
        pass
    
    def poisson_reconstruction(self, pcd: o3d.geometry.PointCloud,
                                depth: int = 9,
                                scale: float = 1.1) -> Tuple[o3d.geometry.TriangleMesh, np.ndarray]:
        """
        Poisson Surface Reconstruction
        
        ë§¤ë„ëŸ¬ìš´ í‘œë©´ ìƒì„±ì— ì í•©
        
        Parameters:
        - depth: ì˜¥íŠ¸ë¦¬ ê¹Šì´ (ë†’ì„ìˆ˜ë¡ ì„¸ë°€)
        - scale: ë°”ìš´ë”© ë°•ìŠ¤ ìŠ¤ì¼€ì¼
        
        Returns:
        - mesh: ìƒì„±ëœ ë©”ì‰¬
        - densities: ë°€ë„ ê°’ (í›„ì²˜ë¦¬ìš©)
        """
        
        print("\nğŸ”¨ Poisson í‘œë©´ ì¬êµ¬ì„±")
        print(f"   ì˜¥íŠ¸ë¦¬ ê¹Šì´: {depth}")
        
        # ë²•ì„  í•„ìš”
        if not pcd.has_normals():
            pcd.estimate_normals(
                search_param=o3d.geometry.KDTreeSearchParamHybrid(
                    radius=10, max_nn=30
                )
            )
            pcd.orient_normals_consistent_tangent_plane(k=15)
        
        # Poisson ì¬êµ¬ì„±
        mesh, densities = o3d.geometry.TriangleMesh.create_from_point_cloud_poisson(
            pcd,
            depth=depth,
            scale=scale,
            linear_fit=False
        )
        
        densities = np.asarray(densities)
        
        print(f"âœ… ë©”ì‰¬ ìƒì„±: {len(mesh.vertices):,} vertices, {len(mesh.triangles):,} triangles")
        
        return mesh, densities
    
    def ball_pivoting(self, pcd: o3d.geometry.PointCloud,
                      radii: list = None) -> o3d.geometry.TriangleMesh:
        """
        Ball Pivoting Algorithm (BPA)
        
        ì›ë³¸ í¬ì¸íŠ¸ë¥¼ ìœ ì§€í•˜ëŠ” í‘œë©´ ìƒì„±
        
        Parameters:
        - radii: êµ¬ì˜ ë°˜ì§€ë¦„ ë¦¬ìŠ¤íŠ¸
        """
        
        print("\nğŸ”¨ Ball Pivoting í‘œë©´ ì¬êµ¬ì„±")
        
        if radii is None:
            # í‰ê·  í¬ì¸íŠ¸ ê±°ë¦¬ ê¸°ë°˜ ìë™ ê³„ì‚°
            distances = pcd.compute_nearest_neighbor_distance()
            avg_dist = np.mean(distances)
            radii = [avg_dist * 1.5, avg_dist * 3, avg_dist * 6]
        
        print(f"   ë°˜ì§€ë¦„: {radii}")
        
        # ë²•ì„  í•„ìš”
        if not pcd.has_normals():
            pcd.estimate_normals(
                search_param=o3d.geometry.KDTreeSearchParamHybrid(
                    radius=10, max_nn=30
                )
            )
        
        # Ball Pivoting
        radii_o3d = o3d.utility.DoubleVector(radii)
        mesh = o3d.geometry.TriangleMesh.create_from_point_cloud_ball_pivoting(
            pcd, radii_o3d
        )
        
        print(f"âœ… ë©”ì‰¬ ìƒì„±: {len(mesh.vertices):,} vertices, {len(mesh.triangles):,} triangles")
        
        return mesh
    
    def alpha_shape(self, pcd: o3d.geometry.PointCloud,
                    alpha: float = 30.0) -> o3d.geometry.TriangleMesh:
        """
        Alpha Shape
        
        Parameters:
        - alpha: ì•ŒíŒŒ ê°’ (ì‘ì„ìˆ˜ë¡ ì„¸ë°€, êµ¬ë© ë§ìŒ)
        """
        
        print(f"\nğŸ”¨ Alpha Shape (alpha={alpha})")
        
        mesh = o3d.geometry.TriangleMesh.create_from_point_cloud_alpha_shape(
            pcd, alpha
        )
        
        print(f"âœ… ë©”ì‰¬ ìƒì„±: {len(mesh.vertices):,} vertices, {len(mesh.triangles):,} triangles")
        
        return mesh
    
    def clean_mesh(self, mesh: o3d.geometry.TriangleMesh,
                   densities: np.ndarray = None,
                   density_threshold: float = 0.1) -> o3d.geometry.TriangleMesh:
        """
        ë©”ì‰¬ ì •ë¦¬
        
        Parameters:
        - densities: Poisson ë°€ë„ ê°’
        - density_threshold: ë°€ë„ ì„ê³„ê°’ (í•˜ìœ„ % ì œê±°)
        """
        
        print("\nğŸ§¹ ë©”ì‰¬ ì •ë¦¬")
        
        # ì €ë°€ë„ ì˜ì—­ ì œê±°
        if densities is not None:
            threshold = np.quantile(densities, density_threshold)
            vertices_to_remove = densities < threshold
            mesh.remove_vertices_by_mask(vertices_to_remove)
            print(f"   ì €ë°€ë„ ì˜ì—­ ì œê±°: {np.sum(vertices_to_remove):,} vertices")
        
        # ì¤‘ë³µ ì œê±°
        mesh.remove_duplicated_vertices()
        mesh.remove_duplicated_triangles()
        
        # í‡´í™” ì‚¼ê°í˜• ì œê±°
        mesh.remove_degenerate_triangles()
        
        # ë¹„ë‹¤ì–‘ì²´ ì—£ì§€ ì œê±°
        mesh.remove_non_manifold_edges()
        
        # ì—°ê²°ë˜ì§€ ì•Šì€ ì‘ì€ ì»´í¬ë„ŒíŠ¸ ì œê±°
        triangle_clusters, cluster_n_triangles, _ = mesh.cluster_connected_triangles()
        triangle_clusters = np.asarray(triangle_clusters)
        cluster_n_triangles = np.asarray(cluster_n_triangles)
        
        # ê°€ì¥ í° í´ëŸ¬ìŠ¤í„°ë§Œ ìœ ì§€
        largest_cluster_idx = np.argmax(cluster_n_triangles)
        triangles_to_remove = triangle_clusters != largest_cluster_idx
        mesh.remove_triangles_by_mask(triangles_to_remove)
        
        # ë²•ì„  ì¬ê³„ì‚°
        mesh.compute_vertex_normals()
        
        print(f"âœ… ì •ë¦¬ ì™„ë£Œ: {len(mesh.vertices):,} vertices, {len(mesh.triangles):,} triangles")
        
        return mesh
    
    def smooth_mesh(self, mesh: o3d.geometry.TriangleMesh,
                    iterations: int = 5,
                    method: str = 'laplacian') -> o3d.geometry.TriangleMesh:
        """
        ë©”ì‰¬ ìŠ¤ë¬´ë”©
        
        Parameters:
        - iterations: ë°˜ë³µ íšŸìˆ˜
        - method: 'laplacian' ë˜ëŠ” 'taubin'
        """
        
        print(f"\nğŸ§´ ë©”ì‰¬ ìŠ¤ë¬´ë”© ({method}, {iterations} iterations)")
        
        if method == 'laplacian':
            smoothed = mesh.filter_smooth_laplacian(
                number_of_iterations=iterations
            )
        elif method == 'taubin':
            smoothed = mesh.filter_smooth_taubin(
                number_of_iterations=iterations
            )
        else:
            smoothed = mesh
        
        smoothed.compute_vertex_normals()
        
        print("âœ… ìŠ¤ë¬´ë”© ì™„ë£Œ")
        
        return smoothed
    
    def simplify_mesh(self, mesh: o3d.geometry.TriangleMesh,
                      target_triangles: int = 50000) -> o3d.geometry.TriangleMesh:
        """
        ë©”ì‰¬ ë‹¨ìˆœí™” (ì‚¼ê°í˜• ìˆ˜ ê°ì†Œ)
        """
        
        original = len(mesh.triangles)
        
        simplified = mesh.simplify_quadric_decimation(
            target_number_of_triangles=target_triangles
        )
        
        simplified.compute_vertex_normals()
        
        print(f"ë©”ì‰¬ ë‹¨ìˆœí™”: {original:,} â†’ {len(simplified.triangles):,} triangles")
        
        return simplified
    
    def add_texture(self, mesh: o3d.geometry.TriangleMesh,
                    pcd: o3d.geometry.PointCloud) -> o3d.geometry.TriangleMesh:
        """
        í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ìƒ‰ìƒì„ ë©”ì‰¬ì— ì ìš©
        """
        
        if not pcd.has_colors():
            print("âš ï¸ í¬ì¸íŠ¸ í´ë¼ìš°ë“œì— ìƒ‰ìƒ ì—†ìŒ")
            return mesh
        
        # ê°€ì¥ ê°€ê¹Œìš´ í¬ì¸íŠ¸ì˜ ìƒ‰ìƒ í• ë‹¹
        pcd_tree = o3d.geometry.KDTreeFlann(pcd)
        mesh_vertices = np.asarray(mesh.vertices)
        pcd_colors = np.asarray(pcd.colors)
        
        vertex_colors = np.zeros((len(mesh_vertices), 3))
        
        for i, vertex in enumerate(mesh_vertices):
            [k, idx, _] = pcd_tree.search_knn_vector_3d(vertex, 1)
            vertex_colors[i] = pcd_colors[idx[0]]
        
        mesh.vertex_colors = o3d.utility.Vector3dVector(vertex_colors)
        
        print("âœ… í…ìŠ¤ì²˜ ì ìš© ì™„ë£Œ")
        
        return mesh
```

---

## 8. íŒŒì¼ ì¶œë ¥

### 8.1 íŒŒì¼ ë‚´ë³´ë‚´ê¸°

```python
"""
file_exporter.py
3D ëª¨ë¸ íŒŒì¼ ì¶œë ¥
"""

import os
import numpy as np
import open3d as o3d
from typing import Optional


class FileExporter:
    """íŒŒì¼ ì¶œë ¥ ê´€ë¦¬"""
    
    def __init__(self, output_dir: str = "output"):
        self.output_dir = output_dir
        
        os.makedirs(os.path.join(output_dir, "pointclouds"), exist_ok=True)
        os.makedirs(os.path.join(output_dir, "meshes"), exist_ok=True)
    
    def export_pointcloud(self, pcd: o3d.geometry.PointCloud,
                          filename: str,
                          format: str = 'ply') -> str:
        """
        í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ë‚´ë³´ë‚´ê¸°
        
        Parameters:
        - pcd: í¬ì¸íŠ¸ í´ë¼ìš°ë“œ
        - filename: íŒŒì¼ëª… (í™•ì¥ì ì œì™¸)
        - format: 'ply', 'pcd', 'xyz', 'pts'
        
        Returns:
        - filepath: ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ
        """
        
        filepath = os.path.join(
            self.output_dir, "pointclouds", f"{filename}.{format}"
        )
        
        success = o3d.io.write_point_cloud(filepath, pcd)
        
        if success:
            size_mb = os.path.getsize(filepath) / (1024 * 1024)
            print(f"âœ… í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ì €ì¥: {filepath} ({size_mb:.1f} MB)")
        else:
            print(f"âŒ ì €ì¥ ì‹¤íŒ¨: {filepath}")
        
        return filepath
    
    def export_mesh(self, mesh: o3d.geometry.TriangleMesh,
                    filename: str,
                    format: str = 'obj') -> str:
        """
        ë©”ì‰¬ ë‚´ë³´ë‚´ê¸°
        
        Parameters:
        - mesh: ë©”ì‰¬
        - filename: íŒŒì¼ëª… (í™•ì¥ì ì œì™¸)
        - format: 'obj', 'ply', 'stl', 'gltf', 'glb'
        
        Returns:
        - filepath: ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ
        """
        
        filepath = os.path.join(
            self.output_dir, "meshes", f"{filename}.{format}"
        )
        
        success = o3d.io.write_triangle_mesh(filepath, mesh)
        
        if success:
            size_mb = os.path.getsize(filepath) / (1024 * 1024)
            print(f"âœ… ë©”ì‰¬ ì €ì¥: {filepath} ({size_mb:.1f} MB)")
            print(f"   ì •ì : {len(mesh.vertices):,}, ì‚¼ê°í˜•: {len(mesh.triangles):,}")
        else:
            print(f"âŒ ì €ì¥ ì‹¤íŒ¨: {filepath}")
        
        return filepath
    
    def export_for_3d_printing(self, mesh: o3d.geometry.TriangleMesh,
                               filename: str,
                               scale: float = 1.0) -> str:
        """
        3D í”„ë¦°íŒ…ìš© STL ë‚´ë³´ë‚´ê¸°
        
        Parameters:
        - scale: ìŠ¤ì¼€ì¼ (1.0 = ì›ë³¸, mm ë‹¨ìœ„)
        """
        
        # ë³µì‚¬
        mesh_copy = o3d.geometry.TriangleMesh(mesh)
        
        # ìŠ¤ì¼€ì¼ ì ìš©
        if scale != 1.0:
            mesh_copy.scale(scale, center=mesh_copy.get_center())
        
        # ì›Œí„°íƒ€ì´íŠ¸ í™•ì¸
        if not mesh_copy.is_watertight():
            print("âš ï¸ ë©”ì‰¬ê°€ ì›Œí„°íƒ€ì´íŠ¸í•˜ì§€ ì•ŠìŒ (êµ¬ë© ìˆìŒ)")
            print("   3D í”„ë¦°íŒ… ì‹œ ë¬¸ì œê°€ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        
        # STL ì €ì¥ (ë°”ì´ë„ˆë¦¬)
        filepath = os.path.join(
            self.output_dir, "meshes", f"{filename}_print.stl"
        )
        
        o3d.io.write_triangle_mesh(filepath, mesh_copy, write_ascii=False)
        
        size_mb = os.path.getsize(filepath) / (1024 * 1024)
        print(f"âœ… 3D í”„ë¦°íŒ…ìš© STL ì €ì¥: {filepath} ({size_mb:.1f} MB)")
        
        # í¬ê¸° ì •ë³´
        bbox = mesh_copy.get_axis_aligned_bounding_box()
        extent = bbox.get_extent()
        print(f"   í¬ê¸°: {extent[0]:.1f} x {extent[1]:.1f} x {extent[2]:.1f} mm")
        
        return filepath
    
    def export_all_formats(self, mesh: o3d.geometry.TriangleMesh,
                           filename: str) -> dict:
        """
        ëª¨ë“  í˜•ì‹ìœ¼ë¡œ ë‚´ë³´ë‚´ê¸°
        """
        
        formats = ['obj', 'ply', 'stl', 'gltf']
        paths = {}
        
        for fmt in formats:
            try:
                path = self.export_mesh(mesh, filename, fmt)
                paths[fmt] = path
            except Exception as e:
                print(f"âš ï¸ {fmt} í˜•ì‹ ì €ì¥ ì‹¤íŒ¨: {e}")
        
        return paths
```

---

## 9. GUI êµ¬í˜„

### 9.1 ìŠ¤ìºë„ˆ GUI

```python
"""
gui.py
3D ìŠ¤ìºë„ˆ GUI
"""

import cv2
import numpy as np
import open3d as o3d
from typing import Optional, List, Callable
import time
import threading


class Scanner3DGUI:
    """3D ìŠ¤ìºë„ˆ GUI"""
    
    def __init__(self, window_name: str = "3D Scanner"):
        self.window_name = window_name
        
        # ìƒíƒœ
        self.current_view = 'camera'  # 'camera', 'preview', 'result'
        
        # FPS
        self.fps_history = []
        self.last_time = time.time()
        
        # 3D ë·°ì–´
        self.vis: Optional[o3d.visualization.Visualizer] = None
        
        cv2.namedWindow(self.window_name, cv2.WINDOW_NORMAL)
    
    def update_fps(self) -> float:
        """FPS ê³„ì‚°"""
        current = time.time()
        fps = 1.0 / (current - self.last_time + 1e-6)
        self.last_time = current
        
        self.fps_history.append(fps)
        if len(self.fps_history) > 30:
            self.fps_history.pop(0)
        
        return np.mean(self.fps_history)
    
    def draw_capture_overlay(self, image: np.ndarray,
                             current_angle: float,
                             num_captured: int,
                             total: int,
                             is_capturing: bool) -> np.ndarray:
        """ìº¡ì²˜ ì˜¤ë²„ë ˆì´"""
        
        h, w = image.shape[:2]
        
        # ìƒíƒœ íŒ¨ë„
        overlay = image.copy()
        cv2.rectangle(overlay, (10, 10), (350, 150), (0, 0, 0), -1)
        cv2.addWeighted(overlay, 0.7, image, 0.3, 0, image)
        
        # í…ìŠ¤íŠ¸
        y = 40
        fps = self.update_fps()
        cv2.putText(image, f"FPS: {fps:.1f}", (20, y),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
        
        y += 30
        cv2.putText(image, f"Angle: {current_angle:.0f}Â°", (20, y),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        
        y += 30
        cv2.putText(image, f"Captures: {num_captured}/{total}", (20, y),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        
        y += 30
        if is_capturing:
            cv2.putText(image, "â— CAPTURING", (20, y),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
        else:
            cv2.putText(image, "â—‹ READY", (20, y),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
        
        # ì§„í–‰ë¥  ë°”
        progress = num_captured / total if total > 0 else 0
        bar_x = 20
        bar_y = 160
        bar_w = 310
        bar_h = 20
        
        cv2.rectangle(image, (bar_x, bar_y), (bar_x + bar_w, bar_y + bar_h),
                     (100, 100, 100), -1)
        cv2.rectangle(image, (bar_x, bar_y), 
                     (bar_x + int(bar_w * progress), bar_y + bar_h),
                     (0, 255, 0), -1)
        cv2.rectangle(image, (bar_x, bar_y), (bar_x + bar_w, bar_y + bar_h),
                     (255, 255, 255), 1)
        
        # ë„ì›€ë§
        help_text = "[SPACE] Capture | [S] Start | [P] Process | [Q] Quit"
        cv2.putText(image, help_text, (20, h - 20),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200, 200, 200), 1)
        
        return image
    
    def draw_processing_overlay(self, image: np.ndarray,
                                 status: str,
                                 progress: float) -> np.ndarray:
        """ì²˜ë¦¬ ì¤‘ ì˜¤ë²„ë ˆì´"""
        
        h, w = image.shape[:2]
        
        # ì–´ë‘¡ê²Œ
        overlay = np.zeros_like(image)
        cv2.addWeighted(image, 0.3, overlay, 0.7, 0, image)
        
        # ìƒíƒœ í…ìŠ¤íŠ¸
        cv2.putText(image, status, (w//2 - 100, h//2),
                   cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
        
        # ì§„í–‰ë¥  ë°”
        bar_w = 400
        bar_h = 30
        bar_x = (w - bar_w) // 2
        bar_y = h // 2 + 40
        
        cv2.rectangle(image, (bar_x, bar_y), (bar_x + bar_w, bar_y + bar_h),
                     (100, 100, 100), -1)
        cv2.rectangle(image, (bar_x, bar_y),
                     (bar_x + int(bar_w * progress), bar_y + bar_h),
                     (0, 200, 255), -1)
        
        cv2.putText(image, f"{progress*100:.0f}%", 
                   (w//2 - 20, bar_y + bar_h + 30),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        
        return image
    
    def show_3d_preview(self, pcd: o3d.geometry.PointCloud):
        """3D ë¯¸ë¦¬ë³´ê¸° (ë³„ë„ ì°½)"""
        
        if self.vis is None:
            self.vis = o3d.visualization.Visualizer()
            self.vis.create_window("3D Preview", width=800, height=600)
            
            opt = self.vis.get_render_option()
            opt.point_size = 2.0
            opt.background_color = np.array([0.1, 0.1, 0.1])
        
        self.vis.clear_geometries()
        self.vis.add_geometry(pcd)
        
        # ì¢Œí‘œì¶•
        coord = o3d.geometry.TriangleMesh.create_coordinate_frame(size=50)
        self.vis.add_geometry(coord)
        
        self.vis.poll_events()
        self.vis.update_renderer()
    
    def show_mesh_result(self, mesh: o3d.geometry.TriangleMesh):
        """ìµœì¢… ë©”ì‰¬ ê²°ê³¼ í‘œì‹œ"""
        
        # ë³„ë„ ì°½ì—ì„œ ìƒí˜¸ì‘ìš© ê°€ëŠ¥í•œ ë·°ì–´
        o3d.visualization.draw_geometries(
            [mesh],
            window_name="3D Scan Result",
            width=1024,
            height=768
        )
    
    def show(self, image: np.ndarray):
        """ì´ë¯¸ì§€ í‘œì‹œ"""
        cv2.imshow(self.window_name, image)
    
    def wait_key(self, delay: int = 1) -> int:
        """í‚¤ ì…ë ¥"""
        return cv2.waitKey(delay) & 0xFF
    
    def close(self):
        """ì¢…ë£Œ"""
        cv2.destroyAllWindows()
        if self.vis:
            self.vis.destroy_window()
```

---

## 10. ì „ì²´ ì½”ë“œ

### 10.1 ë©”ì¸ ì‹¤í–‰ íŒŒì¼

```python
"""
main.py
3D ìŠ¤ìºë„ˆ ë©”ì¸
"""

import argparse
import yaml
import cv2
import numpy as np
import open3d as o3d
import sys
from datetime import datetime

sys.path.append('src')

from stereo_camera import StereoCamera
from scan_session import ScanSessionManager
from capture_controller import CaptureController, CaptureMode
from pointcloud_generator import PointCloudGenerator
from cloud_registration import MultiViewRegistration
from cloud_processor import PointCloudProcessor
from mesh_generator import MeshGenerator
from file_exporter import FileExporter
from gui import Scanner3DGUI


class Scanner3DApp:
    """3D ìŠ¤ìºë„ˆ ì• í”Œë¦¬ì¼€ì´ì…˜"""
    
    def __init__(self, config_file: str):
        with open(config_file, 'r') as f:
            self.config = yaml.safe_load(f)
        
        self._init_components()
        
        print("\n" + "="*60)
        print("ğŸ“¦ 3D ìŠ¤ìºë„ˆ")
        print("="*60)
    
    def _init_components(self):
        """ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”"""
        
        # ìŠ¤í…Œë ˆì˜¤ ì¹´ë©”ë¼
        self.camera = StereoCamera(
            self.config['calibration_file'],
            self.config['camera']['left_id'],
            self.config['camera']['right_id']
        )
        
        # ì„¸ì…˜ ê´€ë¦¬
        self.session_mgr = ScanSessionManager(self.config['output_dir'])
        
        # ìº¡ì²˜ ì»¨íŠ¸ë¡¤ëŸ¬
        self.capture_ctrl = CaptureController(
            self.camera, self.session_mgr,
            CaptureMode.MANUAL
        )
        
        # í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ìƒì„±
        self.pc_generator = PointCloudGenerator(self.config['calibration_file'])
        
        # ì •í•©
        self.registration = MultiViewRegistration(
            voxel_size=self.config['processing']['voxel_size']
        )
        
        # ì²˜ë¦¬
        self.processor = PointCloudProcessor()
        
        # ë©”ì‰¬ ìƒì„±
        self.mesh_generator = MeshGenerator()
        
        # íŒŒì¼ ì¶œë ¥
        self.exporter = FileExporter(self.config['output_dir'])
        
        # GUI
        self.gui = Scanner3DGUI()
        
        # ìƒíƒœ
        self.pointclouds = []
        self.merged_cloud = None
        self.final_mesh = None
    
    def run(self):
        """ë©”ì¸ ë£¨í”„"""
        
        print("\nì¡°ì‘ ë°©ë²•:")
        print("  [N]     - ìƒˆ ìŠ¤ìº” ì„¸ì…˜")
        print("  [S]     - ìº¡ì²˜ ì‹œì‘")
        print("  [SPACE] - ë‹¨ì¼ ìº¡ì²˜")
        print("  [P]     - ì²˜ë¦¬ (ì •í•© + ë©”ì‰¬)")
        print("  [V]     - 3D ë¯¸ë¦¬ë³´ê¸°")
        print("  [E]     - ë‚´ë³´ë‚´ê¸°")
        print("  [Q]     - ì¢…ë£Œ")
        print("="*60 + "\n")
        
        while True:
            # ìº¡ì²˜
            rect_left, rect_right = self.camera.capture_rectified()
            
            if rect_left is None:
                continue
            
            # ìë™ ìº¡ì²˜ ì—…ë°ì´íŠ¸
            self.capture_ctrl.update()
            
            # ì§„í–‰ ìƒí™©
            current, total, angle = self.capture_ctrl.get_progress()
            
            # ë Œë”ë§
            display = self.gui.draw_capture_overlay(
                rect_left.copy(),
                angle,
                current,
                total,
                self.capture_ctrl.is_capturing
            )
            
            self.gui.show(display)
            
            # í‚¤ ì²˜ë¦¬
            key = self.gui.wait_key(1)
            
            if key == ord('q'):
                break
            
            elif key == ord('n'):
                self._new_session()
            
            elif key == ord('s'):
                self._start_capture()
            
            elif key == ord(' '):
                self.capture_ctrl.handle_key(key)
            
            elif key == ord('p'):
                self._process()
            
            elif key == ord('v'):
                self._preview_3d()
            
            elif key == ord('e'):
                self._export()
        
        self._cleanup()
    
    def _new_session(self):
        """ìƒˆ ì„¸ì…˜"""
        
        name = f"scan_{datetime.now().strftime('%H%M%S')}"
        angle_step = self.config['scan']['angle_step']
        
        self.session_mgr.create_session(name, angle_step)
        self.pointclouds = []
        self.merged_cloud = None
        self.final_mesh = None
        
        print(f"âœ… ìƒˆ ì„¸ì…˜: {name}")
    
    def _start_capture(self):
        """ìº¡ì²˜ ì‹œì‘"""
        
        if self.session_mgr.current_session is None:
            self._new_session()
        
        angle_step = self.config['scan']['angle_step']
        self.capture_ctrl.start_capture_sequence(angle_step)
    
    def _process(self):
        """ì²˜ë¦¬ (ì •í•© + ë©”ì‰¬ ìƒì„±)"""
        
        session = self.session_mgr.current_session
        if session is None or len(session.captures) == 0:
            print("âš ï¸ ìº¡ì²˜ëœ ì´ë¯¸ì§€ ì—†ìŒ")
            return
        
        print(f"\nğŸ”„ {len(session.captures)}ê°œ ìº¡ì²˜ ì²˜ë¦¬ ì¤‘...")
        
        # 1. í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ìƒì„±
        self.pointclouds = []
        angles = []
        
        for capture in session.captures:
            pcd = self.pc_generator.generate_from_files(
                capture.left_image_path,
                capture.right_image_path,
                min_depth=self.config['processing']['min_depth'],
                max_depth=self.config['processing']['max_depth']
            )
            
            # ë°°ê²½ ì œê±° (í‰ë©´)
            from background_removal import BackgroundRemover
            bg_remover = BackgroundRemover()
            pcd = bg_remover.remove_plane(pcd, distance_threshold=20)
            
            self.pointclouds.append(pcd)
            angles.append(capture.angle)
            
            print(f"  ìº¡ì²˜ #{capture.frame_id}: {len(pcd.points):,} points")
        
        # 2. ì •í•©
        self.merged_cloud = self.registration.register_sequential(
            self.pointclouds, angles
        )
        
        # 3. í›„ì²˜ë¦¬
        self.merged_cloud = self.processor.process_pipeline(
            self.merged_cloud,
            voxel_size=self.config['processing']['voxel_size']
        )
        
        # 4. ë©”ì‰¬ ìƒì„±
        self.final_mesh, densities = self.mesh_generator.poisson_reconstruction(
            self.merged_cloud,
            depth=self.config['mesh']['poisson_depth']
        )
        
        # ë©”ì‰¬ ì •ë¦¬
        self.final_mesh = self.mesh_generator.clean_mesh(
            self.final_mesh, densities,
            density_threshold=0.1
        )
        
        # ìƒ‰ìƒ ì ìš©
        self.final_mesh = self.mesh_generator.add_texture(
            self.final_mesh, self.merged_cloud
        )
        
        # ìŠ¤ë¬´ë”©
        self.final_mesh = self.mesh_generator.smooth_mesh(
            self.final_mesh, iterations=3
        )
        
        print("\nâœ… ì²˜ë¦¬ ì™„ë£Œ!")
    
    def _preview_3d(self):
        """3D ë¯¸ë¦¬ë³´ê¸°"""
        
        if self.merged_cloud is not None:
            self.gui.show_3d_preview(self.merged_cloud)
        elif len(self.pointclouds) > 0:
            self.gui.show_3d_preview(self.pointclouds[-1])
        else:
            print("âš ï¸ ë¯¸ë¦¬ë³´ê¸°í•  ë°ì´í„° ì—†ìŒ")
    
    def _export(self):
        """ë‚´ë³´ë‚´ê¸°"""
        
        session = self.session_mgr.current_session
        if session is None:
            print("âš ï¸ ì„¸ì…˜ ì—†ìŒ")
            return
        
        name = session.name
        
        # í¬ì¸íŠ¸ í´ë¼ìš°ë“œ
        if self.merged_cloud is not None:
            self.exporter.export_pointcloud(self.merged_cloud, f"{name}_cloud", 'ply')
        
        # ë©”ì‰¬
        if self.final_mesh is not None:
            self.exporter.export_mesh(self.final_mesh, f"{name}_mesh", 'obj')
            self.exporter.export_for_3d_printing(self.final_mesh, name)
        
        print("âœ… ë‚´ë³´ë‚´ê¸° ì™„ë£Œ")
    
    def _cleanup(self):
        """ì •ë¦¬"""
        self.camera.release()
        self.gui.close()
        print("\ní”„ë¡œê·¸ë¨ ì¢…ë£Œ")


def main():
    parser = argparse.ArgumentParser(description='3D ìŠ¤ìºë„ˆ')
    parser.add_argument('--config', default='config/scanner_config.yaml')
    args = parser.parse_args()
    
    app = Scanner3DApp(args.config)
    app.run()


if __name__ == "__main__":
    main()
```

### 10.2 ì„¤ì • íŒŒì¼

```yaml
# config/scanner_config.yaml

calibration_file: "config/stereo_params.yaml"
output_dir: "output/projects"

camera:
  left_id: 0
  right_id: 2
  width: 1280
  height: 720

scan:
  angle_step: 30          # 30Â° ê°„ê²© = 12 ìº¡ì²˜
  capture_mode: "manual"  # manual, timed

processing:
  min_depth: 200          # mm
  max_depth: 1000         # mm
  voxel_size: 2.0         # mm

mesh:
  method: "poisson"       # poisson, ball_pivoting
  poisson_depth: 9
  smooth_iterations: 3

export:
  formats: ["obj", "stl", "ply"]
  scale_for_print: 1.0
```

---

## ğŸ“ í•™ìŠµ ì²´í¬ë¦¬ìŠ¤íŠ¸

### êµ¬í˜„ ì™„ë£Œ

- [ ] ë‹¤ì¤‘ ì‹œì  ìº¡ì²˜ ì‹œìŠ¤í…œ
- [ ] í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ìƒì„±
- [ ] ë°°ê²½/í‰ë©´ ì œê±°
- [ ] ICP ê¸°ë°˜ ì •í•©
- [ ] í¬ì¸íŠ¸ í´ë¼ìš°ë“œ í›„ì²˜ë¦¬
- [ ] Poisson ë©”ì‰¬ ìƒì„±
- [ ] íŒŒì¼ ì¶œë ¥ (OBJ, STL, PLY)
- [ ] GUI êµ¬í˜„

### í…ŒìŠ¤íŠ¸ ì™„ë£Œ

- [ ] ë‹¨ì¼ ìº¡ì²˜ í¬ì¸íŠ¸ í´ë¼ìš°ë“œ í’ˆì§ˆ
- [ ] ë‹¤ì¤‘ ì‹œì  ì •í•© ì •í™•ë„
- [ ] ë©”ì‰¬ í’ˆì§ˆ (ì›Œí„°íƒ€ì´íŠ¸, êµ¬ë©)
- [ ] 3D í”„ë¦°íŒ… í˜¸í™˜ì„±

---

## â¡ï¸ ë‹¤ìŒ í”„ë¡œì íŠ¸

**[Project 04: Visual Odometry](../Project_04_Visual_Odometry/README.md)**

ë‹¤ìŒ í”„ë¡œì íŠ¸ì—ì„œëŠ”:
- ìŠ¤í…Œë ˆì˜¤ Visual Odometry
- íŠ¹ì§•ì  ì¶”ì 
- ëª¨ì…˜ ì¶”ì •
- ê¶¤ì  ì‹œê°í™”

ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.

---

## ğŸ“„ ë¼ì´ì„ ìŠ¤

MIT License - ììœ ë¡­ê²Œ ì‚¬ìš©, ìˆ˜ì •, ë°°í¬ ê°€ëŠ¥
