# Project 02: ì¥ì• ë¬¼ ê°ì§€ ì‹œìŠ¤í…œ

[![ë‚œì´ë„](https://img.shields.io/badge/ë‚œì´ë„-â­â­â­â­_ê³ ê¸‰-red.svg)]()
[![ì˜ˆìƒì‹œê°„](https://img.shields.io/badge/ì˜ˆìƒì‹œê°„-10--15ì‹œê°„-blue.svg)]()
[![ì„ ìˆ˜ì§€ì‹](https://img.shields.io/badge/ì„ ìˆ˜ì§€ì‹-Project_01_ì™„ë£Œ-orange.svg)]()

---

## ğŸ¯ í”„ë¡œì íŠ¸ ê°œìš”

| í•­ëª© | ë‚´ìš© |
|------|------|
| **ëª©í‘œ** | ìŠ¤í…Œë ˆì˜¤ ì¹´ë©”ë¼ ê¸°ë°˜ ì‹¤ì‹œê°„ ì¥ì• ë¬¼ ê°ì§€ ë° ê²½ê³  ì‹œìŠ¤í…œ |
| **ê¸°ëŠ¥** | ê±°ë¦¬ë³„ ìœ„í—˜ ì˜ì—­ ê°ì§€, ì¶©ëŒ ê²½ê³ , ì•ˆì „ ì˜ì—­ ì‹œê°í™” |
| **ì‘ìš©** | ë¡œë´‡ ë„¤ë¹„ê²Œì´ì…˜, ììœ¨ì£¼í–‰, ë“œë¡  ì¥ì• ë¬¼ íšŒí”¼, ì‹œê° ë³´ì¡° |

---

## ğŸ“‹ ëª©ì°¨

1. [í”„ë¡œì íŠ¸ êµ¬ì¡°](#1-í”„ë¡œì íŠ¸-êµ¬ì¡°) : ë””ë ‰í† ë¦¬ êµ¬ì¡°, ëª¨ë“ˆ êµ¬ì„±
2. [ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜](#2-ì‹œìŠ¤í…œ-ì•„í‚¤í…ì²˜) : ì „ì²´ íŒŒì´í”„ë¼ì¸ (ìº¡ì²˜â†’ê°ì§€â†’ì¶”ì â†’ê²½ê³ )
3. [ì¥ì• ë¬¼ ê°ì§€ ì•Œê³ ë¦¬ì¦˜](#3-ì¥ì• ë¬¼-ê°ì§€-ì•Œê³ ë¦¬ì¦˜) : ObstacleDetector, GroundPlaneRemover, U-Disparity
4. [ìœ„í—˜ ì˜ì—­ ë¶„ë¥˜](#4-ìœ„í—˜-ì˜ì—­-ë¶„ë¥˜) : 5ë‹¨ê³„ (SAFEâ†’CRITICAL), ê±°ë¦¬ ì„ê³„ê°’
5. [ê²½ê³  ì‹œìŠ¤í…œ](#5-ê²½ê³ -ì‹œìŠ¤í…œ) : ì‹œê°/ì²­ê° ê²½ê³ , ê±°ë¦¬ ë°”, ê²½ê³  ì˜¤ë²„ë ˆì´
6. [ì˜ì—­ ë¶„í• ](#6-ì˜ì—­-ë¶„í• ) : ZoneManager, ì‚¬ë‹¤ë¦¬ê¼´ ì˜ì—­, ì ìœ  ê·¸ë¦¬ë“œ
7. [ì¶”ì  ë° ì˜ˆì¸¡](#7-ì¶”ì -ë°-ì˜ˆì¸¡) : SimpleTracker, ì¶©ëŒ ì˜ˆì¸¡ (TTC)
8. [GUI êµ¬í˜„](#8-gui-êµ¬í˜„) : ë°”ìš´ë”© ë°•ìŠ¤, ì¶”ì  ê²½ë¡œ, ë¯¸ë‹ˆë§µ
9. [ì „ì²´ ì½”ë“œ](#9-ì „ì²´-ì½”ë“œ) : main.py, ì„¤ì • íŒŒì¼
10. [ì„±ëŠ¥ ìµœì í™”](#10-ì„±ëŠ¥-ìµœì í™”) : ìµœì í™” ê°€ì´ë“œ

ğŸ“ í¬í•¨ëœ ì™„ì „í•œ ì½”ë“œ
   * obstacle_detector.py - ì¥ì• ë¬¼ ê°ì§€ (DangerLevel, Obstacle, ObstacleDetector)
   * u_disparity.py - U/V-Disparity ê¸°ë°˜ ê°ì§€
   * zone_manager.py - ê°ì§€ ì˜ì—­ ê´€ë¦¬ (ZoneManager, DetectionZone)
   * alert_system.py - ê²½ê³  ì‹œìŠ¤í…œ (ì‹œê°/ì²­ê°)
   * segmentation.py - ê¹Šì´ ê¸°ë°˜ ì˜ì—­ ë¶„í• , ì ìœ  ê·¸ë¦¬ë“œ
   * object_tracker.py - ê°ì²´ ì¶”ì  (SimpleTracker, TrackedObject)
   * gui.py - GUI (ë¯¸ë‹ˆë§µ, ì •ë³´ íŒ¨ë„, ê²½ê³  ì˜¤ë²„ë ˆì´)
   * main.py - ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜
   * detection_config.yaml - ì„¤ì • íŒŒì¼

## ğŸ”§ ê¸°ëŠ¥ ì„¤ëª…

| êµ¬ë¶„ | ê¸°ëŠ¥ í•­ëª© | ì„¤ëª… |
|------|-----------|------|
| ìœ„í—˜ ë¶„ë¥˜ | 5ë‹¨ê³„ ìœ„í—˜ ë¶„ë¥˜ | SAFE â†’ CAUTION â†’ WARNING â†’ DANGER â†’ CRITICAL |
| ì˜ì—­ ì¸ì‹ | ë‹¤ì¤‘ ì˜ì—­ ê°ì§€ | ì¤‘ì•™ / ì¢Œ / ìš° / í•˜ë‹¨ / ì‚¬ìš©ì ì •ì˜ ì˜ì—­ |
| ê°ì²´ ì¸ì‹ | ì‹¤ì‹œê°„ ì¶”ì  | IOU ê¸°ë°˜ ê°ì²´ ì¶”ì , ì´ë™ ê²½ë¡œ í‘œì‹œ |
| ì¶©ëŒ íŒë‹¨ | ì¶©ëŒ ì˜ˆì¸¡ | TTC (Time To Collision) ê³„ì‚° |
| ì‹œê° ì•Œë¦¼ | ì‹œê°ì  ê²½ê³  | í…Œë‘ë¦¬ ìƒ‰ìƒ ë³€ê²½, ê¹œë¹¡ì„, ê²½ê³  í…ìŠ¤íŠ¸ í‘œì‹œ |
| ì‹œê°í™” | ë¯¸ë‹ˆë§µ | íƒ‘ë·° í˜•íƒœì˜ ì¥ì• ë¬¼ ìœ„ì¹˜ í‘œì‹œ |
| ì „ì²˜ë¦¬ | ì§€ë©´ ì œê±° | ê¸°í•˜í•™ì  / RANSAC ë°©ì‹ |


---

## 1. í”„ë¡œì íŠ¸ êµ¬ì¡°

```
Project_02_Obstacle_Detection/
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ stereo_params.yaml      # ìº˜ë¦¬ë¸Œë ˆì´ì…˜
â”‚   â”œâ”€â”€ detection_config.yaml   # ê°ì§€ ì„¤ì •
â”‚   â””â”€â”€ alert_config.yaml       # ê²½ê³  ì„¤ì •
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                 # ë©”ì¸ ì‹¤í–‰
â”‚   â”œâ”€â”€ stereo_camera.py        # ìŠ¤í…Œë ˆì˜¤ ì¹´ë©”ë¼
â”‚   â”œâ”€â”€ depth_processor.py      # ê¹Šì´ ì²˜ë¦¬
â”‚   â”œâ”€â”€ obstacle_detector.py    # ì¥ì• ë¬¼ ê°ì§€
â”‚   â”œâ”€â”€ zone_manager.py         # ì˜ì—­ ê´€ë¦¬
â”‚   â”œâ”€â”€ alert_system.py         # ê²½ê³  ì‹œìŠ¤í…œ
â”‚   â”œâ”€â”€ object_tracker.py       # ê°ì²´ ì¶”ì 
â”‚   â”œâ”€â”€ gui.py                  # GUI
â”‚   â””â”€â”€ utils.py                # ìœ í‹¸ë¦¬í‹°
â”œâ”€â”€ assets/
â”‚   â””â”€â”€ sounds/                 # ê²½ê³ ìŒ
â”‚       â”œâ”€â”€ warning_low.wav
â”‚       â”œâ”€â”€ warning_medium.wav
â”‚       â””â”€â”€ warning_high.wav
â””â”€â”€ logs/
    â””â”€â”€ detection_log.csv       # ê°ì§€ ë¡œê·¸
```

---

## 2. ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 ì¥ì• ë¬¼ ê°ì§€ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                              â”‚
â”‚   â”‚ Camera  â”‚     â”‚ Camera  â”‚                              â”‚
â”‚   â”‚  Left   â”‚     â”‚  Right  â”‚                              â”‚
â”‚   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                              â”‚
â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                                    â”‚
â”‚                â–¼                                            â”‚
â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                    â”‚
â”‚        â”‚ Stereo       â”‚                                    â”‚
â”‚        â”‚ Processing   â”‚                                    â”‚
â”‚        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                                    â”‚
â”‚                â–¼                                            â”‚
â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                    â”‚
â”‚        â”‚  Depth Map   â”‚                                    â”‚
â”‚        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                                    â”‚
â”‚                â”‚                                            â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                â”‚
â”‚     â–¼          â–¼          â–¼                                â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
â”‚ â”‚Ground  â”‚ â”‚Obstacleâ”‚ â”‚ Zone   â”‚                          â”‚
â”‚ â”‚Removal â”‚ â”‚Detect  â”‚ â”‚Classifyâ”‚                          â”‚
â”‚ â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                          â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                â”‚
â”‚                â–¼                                            â”‚
â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                    â”‚
â”‚        â”‚   Object     â”‚                                    â”‚
â”‚        â”‚   Tracker    â”‚                                    â”‚
â”‚        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                                    â”‚
â”‚                â”‚                                            â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                â”‚
â”‚     â–¼          â–¼          â–¼                                â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
â”‚ â”‚ Alert  â”‚ â”‚  GUI   â”‚ â”‚  Log   â”‚                          â”‚
â”‚ â”‚ System â”‚ â”‚Display â”‚ â”‚ Output â”‚                          â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 3. ì¥ì• ë¬¼ ê°ì§€ ì•Œê³ ë¦¬ì¦˜

### 3.1 ê¹Šì´ ê¸°ë°˜ ì¥ì• ë¬¼ ê°ì§€

```python
"""
obstacle_detector.py
ì¥ì• ë¬¼ ê°ì§€ í•µì‹¬ ëª¨ë“ˆ
"""

import cv2
import numpy as np
from typing import List, Tuple, Optional
from dataclasses import dataclass
from enum import Enum


class DangerLevel(Enum):
    """ìœ„í—˜ ìˆ˜ì¤€"""
    SAFE = 0        # ì•ˆì „
    CAUTION = 1     # ì£¼ì˜
    WARNING = 2     # ê²½ê³ 
    DANGER = 3      # ìœ„í—˜
    CRITICAL = 4    # ê¸´ê¸‰


@dataclass
class Obstacle:
    """ì¥ì• ë¬¼ ì •ë³´"""
    id: int
    bbox: Tuple[int, int, int, int]  # x, y, w, h
    center: Tuple[int, int]           # ì¤‘ì‹¬ ì¢Œí‘œ
    distance_mm: float                # ê±°ë¦¬
    area: int                         # í”½ì…€ ë©´ì 
    danger_level: DangerLevel         # ìœ„í—˜ ìˆ˜ì¤€
    velocity: Tuple[float, float] = (0, 0)  # ì´ë™ ì†ë„ (ì„ íƒ)


class ObstacleDetector:
    """ì¥ì• ë¬¼ ê°ì§€ê¸°"""
    
    def __init__(self, config: dict):
        """
        Parameters:
        - config: ê°ì§€ ì„¤ì • ë”•ì…”ë„ˆë¦¬
        """
        
        # ê±°ë¦¬ ì„ê³„ê°’ (mm)
        self.distance_thresholds = config.get('distance_thresholds', {
            'critical': 500,   # 0.5m ì´ë‚´: ê¸´ê¸‰
            'danger': 1000,    # 1m ì´ë‚´: ìœ„í—˜
            'warning': 2000,   # 2m ì´ë‚´: ê²½ê³ 
            'caution': 3000,   # 3m ì´ë‚´: ì£¼ì˜
        })
        
        # ìµœì†Œ/ìµœëŒ€ ê°ì§€ ê±°ë¦¬
        self.min_distance = config.get('min_distance', 200)   # 20cm
        self.max_distance = config.get('max_distance', 5000)  # 5m
        
        # ìµœì†Œ ì¥ì• ë¬¼ í¬ê¸° (í”½ì…€)
        self.min_obstacle_area = config.get('min_obstacle_area', 500)
        
        # ì§€ë©´ ì œê±° ì„¤ì •
        self.ground_removal = config.get('ground_removal', True)
        self.ground_threshold = config.get('ground_threshold', 0.1)  # í•˜ë‹¨ 10%
        
        # í˜•íƒœí•™ì  ì—°ì‚° ì»¤ë„
        self.morph_kernel = cv2.getStructuringElement(
            cv2.MORPH_ELLIPSE, (5, 5)
        )
        
        # ì¥ì• ë¬¼ ID ì¹´ìš´í„°
        self.next_id = 0
    
    def detect(self, depth: np.ndarray, 
               color_image: Optional[np.ndarray] = None) -> List[Obstacle]:
        """
        ì¥ì• ë¬¼ ê°ì§€
        
        Parameters:
        - depth: ê¹Šì´ ë§µ (mm)
        - color_image: ì»¬ëŸ¬ ì´ë¯¸ì§€ (ì„ íƒ, ì‹œê°í™”ìš©)
        
        Returns:
        - obstacles: ê°ì§€ëœ ì¥ì• ë¬¼ ë¦¬ìŠ¤íŠ¸
        """
        
        h, w = depth.shape
        
        # 1. ìœ íš¨ ê¹Šì´ ë§ˆìŠ¤í¬
        valid_mask = (depth > self.min_distance) & (depth < self.max_distance)
        
        # 2. ì§€ë©´ ì œê±° (ì„ íƒ)
        if self.ground_removal:
            ground_y = int(h * (1 - self.ground_threshold))
            valid_mask[ground_y:, :] = False
        
        # 3. ê±°ë¦¬ë³„ ë§ˆìŠ¤í¬ ìƒì„±
        obstacle_mask = np.zeros((h, w), dtype=np.uint8)
        
        # ê°€ê¹Œìš´ ë¬¼ì²´ì¼ìˆ˜ë¡ ì¥ì• ë¬¼ë¡œ íŒë‹¨
        close_mask = valid_mask & (depth < self.distance_thresholds['caution'])
        obstacle_mask[close_mask] = 255
        
        # 4. ë…¸ì´ì¦ˆ ì œê±° (í˜•íƒœí•™ì  ì—°ì‚°)
        obstacle_mask = cv2.morphologyEx(obstacle_mask, cv2.MORPH_OPEN, 
                                         self.morph_kernel)
        obstacle_mask = cv2.morphologyEx(obstacle_mask, cv2.MORPH_CLOSE, 
                                         self.morph_kernel)
        
        # 5. ì—°ê²° ìš”ì†Œ ë¶„ì„
        num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(
            obstacle_mask, connectivity=8
        )
        
        obstacles = []
        
        for i in range(1, num_labels):  # 0ì€ ë°°ê²½
            area = stats[i, cv2.CC_STAT_AREA]
            
            # ìµœì†Œ í¬ê¸° í•„í„°
            if area < self.min_obstacle_area:
                continue
            
            # ë°”ìš´ë”© ë°•ìŠ¤
            x = stats[i, cv2.CC_STAT_LEFT]
            y = stats[i, cv2.CC_STAT_TOP]
            w_box = stats[i, cv2.CC_STAT_WIDTH]
            h_box = stats[i, cv2.CC_STAT_HEIGHT]
            
            # ì¤‘ì‹¬ ì¢Œí‘œ
            cx, cy = int(centroids[i][0]), int(centroids[i][1])
            
            # í•´ë‹¹ ì˜ì—­ì˜ í‰ê·  ê±°ë¦¬
            region_mask = labels == i
            region_depths = depth[region_mask]
            valid_depths = region_depths[region_depths > 0]
            
            if len(valid_depths) == 0:
                continue
            
            mean_distance = np.mean(valid_depths)
            
            # ìœ„í—˜ ìˆ˜ì¤€ ê²°ì •
            danger_level = self._classify_danger(mean_distance)
            
            obstacle = Obstacle(
                id=self.next_id,
                bbox=(x, y, w_box, h_box),
                center=(cx, cy),
                distance_mm=mean_distance,
                area=area,
                danger_level=danger_level
            )
            
            obstacles.append(obstacle)
            self.next_id += 1
        
        # ê±°ë¦¬ìˆœ ì •ë ¬ (ê°€ê¹Œìš´ ê²ƒ ë¨¼ì €)
        obstacles.sort(key=lambda o: o.distance_mm)
        
        return obstacles
    
    def _classify_danger(self, distance_mm: float) -> DangerLevel:
        """ê±°ë¦¬ì— ë”°ë¥¸ ìœ„í—˜ ìˆ˜ì¤€ ë¶„ë¥˜"""
        
        if distance_mm < self.distance_thresholds['critical']:
            return DangerLevel.CRITICAL
        elif distance_mm < self.distance_thresholds['danger']:
            return DangerLevel.DANGER
        elif distance_mm < self.distance_thresholds['warning']:
            return DangerLevel.WARNING
        elif distance_mm < self.distance_thresholds['caution']:
            return DangerLevel.CAUTION
        else:
            return DangerLevel.SAFE
    
    def detect_in_zone(self, depth: np.ndarray,
                       zone_mask: np.ndarray) -> List[Obstacle]:
        """
        íŠ¹ì • ì˜ì—­ ë‚´ ì¥ì• ë¬¼ ê°ì§€
        
        Parameters:
        - depth: ê¹Šì´ ë§µ
        - zone_mask: ê´€ì‹¬ ì˜ì—­ ë§ˆìŠ¤í¬
        
        Returns:
        - obstacles: ì˜ì—­ ë‚´ ì¥ì• ë¬¼
        """
        
        # ì˜ì—­ ì™¸ë¶€ ì œê±°
        masked_depth = depth.copy()
        masked_depth[~zone_mask.astype(bool)] = 0
        
        return self.detect(masked_depth)
    
    def get_closest_obstacle(self, obstacles: List[Obstacle]) -> Optional[Obstacle]:
        """ê°€ì¥ ê°€ê¹Œìš´ ì¥ì• ë¬¼ ë°˜í™˜"""
        
        if not obstacles:
            return None
        
        return min(obstacles, key=lambda o: o.distance_mm)
    
    def get_obstacles_by_danger(self, obstacles: List[Obstacle],
                                 min_level: DangerLevel) -> List[Obstacle]:
        """íŠ¹ì • ìœ„í—˜ ìˆ˜ì¤€ ì´ìƒì˜ ì¥ì• ë¬¼ í•„í„°"""
        
        return [o for o in obstacles if o.danger_level.value >= min_level.value]


class GroundPlaneRemover:
    """ì§€ë©´ í‰ë©´ ì œê±°"""
    
    def __init__(self, camera_height_mm: float = 500,
                 camera_tilt_deg: float = 0):
        """
        Parameters:
        - camera_height_mm: ì¹´ë©”ë¼ ë†’ì´ (mm)
        - camera_tilt_deg: ì¹´ë©”ë¼ ê¸°ìš¸ê¸° (ë„)
        """
        
        self.camera_height = camera_height_mm
        self.camera_tilt = np.radians(camera_tilt_deg)
    
    def remove_ground(self, depth: np.ndarray, 
                      focal_length: float,
                      cy: float) -> np.ndarray:
        """
        ì§€ë©´ ì œê±° (ê¸°í•˜í•™ì  ë°©ë²•)
        
        ì¹´ë©”ë¼ ë†’ì´ì™€ ê¸°ìš¸ê¸°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì§€ë©´ ì¶”ì •
        
        Returns:
        - filtered_depth: ì§€ë©´ì´ ì œê±°ëœ ê¹Šì´ ë§µ
        """
        
        h, w = depth.shape
        
        # ê° í–‰ì˜ ì˜ˆìƒ ì§€ë©´ ê±°ë¦¬ ê³„ì‚°
        v = np.arange(h)
        
        # ì¹´ë©”ë¼ ê¸°í•˜í•™
        # y = cy + f * tan(theta)
        # Z = H / sin(theta)
        
        theta = np.arctan2(v - cy, focal_length) + self.camera_tilt
        
        # ì§€ë©´ìœ¼ë¡œ ì˜ˆìƒë˜ëŠ” ê±°ë¦¬
        expected_ground_distance = np.where(
            theta > 0,
            self.camera_height / np.sin(theta + 1e-6),
            np.inf
        )
        
        # ë§ˆìŠ¤í¬ ìƒì„±
        filtered_depth = depth.copy()
        
        for row in range(h):
            ground_dist = expected_ground_distance[row]
            tolerance = 0.2 * ground_dist  # 20% í—ˆìš© ì˜¤ì°¨
            
            ground_mask = np.abs(depth[row] - ground_dist) < tolerance
            filtered_depth[row, ground_mask] = 0
        
        return filtered_depth
    
    def remove_ground_ransac(self, points_3d: np.ndarray,
                             threshold: float = 50) -> np.ndarray:
        """
        RANSAC ê¸°ë°˜ ì§€ë©´ ì œê±°
        
        Parameters:
        - points_3d: [N, 3] 3D í¬ì¸íŠ¸
        - threshold: ì¸ë¼ì´ì–´ ê±°ë¦¬ ì„ê³„ê°’ (mm)
        
        Returns:
        - mask: ì§€ë©´ì´ ì•„ë‹Œ í¬ì¸íŠ¸ ë§ˆìŠ¤í¬
        """
        
        if len(points_3d) < 100:
            return np.ones(len(points_3d), dtype=bool)
        
        # RANSAC íŒŒë¼ë¯¸í„°
        n_iterations = 100
        best_inliers = 0
        best_plane = None
        
        for _ in range(n_iterations):
            # 3ê°œ ëœë¤ í¬ì¸íŠ¸ ì„ íƒ
            idx = np.random.choice(len(points_3d), 3, replace=False)
            p1, p2, p3 = points_3d[idx]
            
            # í‰ë©´ ë°©ì •ì‹ ê³„ì‚° (ax + by + cz + d = 0)
            v1 = p2 - p1
            v2 = p3 - p1
            normal = np.cross(v1, v2)
            
            if np.linalg.norm(normal) < 1e-6:
                continue
            
            normal = normal / np.linalg.norm(normal)
            d = -np.dot(normal, p1)
            
            # ì§€ë©´ì€ ëŒ€ëµ ìˆ˜í‰ (normalì˜ y ì„±ë¶„ì´ í¼)
            if abs(normal[1]) < 0.8:  # yê°€ ìœ„/ì•„ë˜ ë°©í–¥
                continue
            
            # ì¸ë¼ì´ì–´ ê³„ì‚°
            distances = np.abs(np.dot(points_3d, normal) + d)
            inliers = np.sum(distances < threshold)
            
            if inliers > best_inliers:
                best_inliers = inliers
                best_plane = (normal, d)
        
        if best_plane is None:
            return np.ones(len(points_3d), dtype=bool)
        
        normal, d = best_plane
        distances = np.abs(np.dot(points_3d, normal) + d)
        
        # ì§€ë©´ì´ ì•„ë‹Œ í¬ì¸íŠ¸ (ê±°ë¦¬ê°€ ì„ê³„ê°’ ì´ìƒ)
        mask = distances >= threshold
        
        return mask
```

### 3.2 U-Disparity ê¸°ë°˜ ì¥ì• ë¬¼ ê°ì§€

```python
"""
u_disparity.py
U-Disparityë¥¼ ì´ìš©í•œ ì¥ì• ë¬¼ ê°ì§€
"""

import cv2
import numpy as np
from typing import List, Tuple


class UDisparityDetector:
    """
    U-Disparity ê¸°ë°˜ ì¥ì• ë¬¼ ê°ì§€
    
    U-Disparity: ì‹œì°¨ ë§µì˜ ì—´(column) íˆìŠ¤í† ê·¸ë¨
    - ìˆ˜ì§ì„ ìƒì˜ ì‹œì°¨ ë¶„í¬ ë¶„ì„
    - ì§€ë©´ê³¼ ì¥ì• ë¬¼ ë¶„ë¦¬ì— íš¨ê³¼ì 
    """
    
    def __init__(self, max_disparity: int = 128):
        self.max_disparity = max_disparity
    
    def compute_u_disparity(self, disparity: np.ndarray) -> np.ndarray:
        """
        U-Disparity ì´ë¯¸ì§€ ê³„ì‚°
        
        Parameters:
        - disparity: ì‹œì°¨ ë§µ
        
        Returns:
        - u_disp: U-Disparity ì´ë¯¸ì§€ [width, max_disparity]
        """
        
        h, w = disparity.shape
        u_disp = np.zeros((self.max_disparity, w), dtype=np.float32)
        
        for col in range(w):
            column = disparity[:, col]
            valid = (column > 0) & (column < self.max_disparity)
            
            if np.any(valid):
                # íˆìŠ¤í† ê·¸ë¨
                hist, _ = np.histogram(
                    column[valid].astype(int),
                    bins=self.max_disparity,
                    range=(0, self.max_disparity)
                )
                u_disp[:, col] = hist
        
        return u_disp
    
    def compute_v_disparity(self, disparity: np.ndarray) -> np.ndarray:
        """
        V-Disparity ì´ë¯¸ì§€ ê³„ì‚° (ì§€ë©´ ê²€ì¶œìš©)
        
        Returns:
        - v_disp: V-Disparity ì´ë¯¸ì§€ [height, max_disparity]
        """
        
        h, w = disparity.shape
        v_disp = np.zeros((h, self.max_disparity), dtype=np.float32)
        
        for row in range(h):
            row_data = disparity[row, :]
            valid = (row_data > 0) & (row_data < self.max_disparity)
            
            if np.any(valid):
                hist, _ = np.histogram(
                    row_data[valid].astype(int),
                    bins=self.max_disparity,
                    range=(0, self.max_disparity)
                )
                v_disp[row, :] = hist
        
        return v_disp
    
    def detect_ground_line(self, v_disp: np.ndarray) -> Tuple[float, float]:
        """
        V-Disparityì—ì„œ ì§€ë©´ ì§ì„  ê²€ì¶œ (Hough ë³€í™˜)
        
        Returns:
        - slope, intercept: ì§ì„  íŒŒë¼ë¯¸í„° (y = slope * d + intercept)
        """
        
        # ì´ì§„í™”
        _, binary = cv2.threshold(
            v_disp.astype(np.uint8), 
            5, 255, cv2.THRESH_BINARY
        )
        
        # Hough ì§ì„  ê²€ì¶œ
        lines = cv2.HoughLines(binary, 1, np.pi / 180, threshold=50)
        
        if lines is None or len(lines) == 0:
            return 0, 0
        
        # ê°€ì¥ ê°•í•œ ì§ì„  ì„ íƒ
        rho, theta = lines[0][0]
        
        # y = slope * x + intercept í˜•íƒœë¡œ ë³€í™˜
        if abs(np.sin(theta)) > 0.01:
            slope = -np.cos(theta) / np.sin(theta)
            intercept = rho / np.sin(theta)
        else:
            slope = 0
            intercept = rho
        
        return slope, intercept
    
    def detect_obstacles_from_u_disparity(self, 
                                           u_disp: np.ndarray,
                                           disparity: np.ndarray,
                                           threshold: int = 10) -> List[dict]:
        """
        U-Disparityì—ì„œ ì¥ì• ë¬¼ ê²€ì¶œ
        
        Returns:
        - obstacles: [{'x_range': (x1, x2), 'disparity': d}, ...]
        """
        
        # U-Disparity ì´ì§„í™”
        u_disp_norm = cv2.normalize(u_disp, None, 0, 255, cv2.NORM_MINMAX)
        _, binary = cv2.threshold(
            u_disp_norm.astype(np.uint8),
            threshold, 255, cv2.THRESH_BINARY
        )
        
        # ì—°ê²° ìš”ì†Œ ë¶„ì„
        num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(
            binary, connectivity=8
        )
        
        obstacles = []
        
        for i in range(1, num_labels):
            x = stats[i, cv2.CC_STAT_LEFT]
            w = stats[i, cv2.CC_STAT_WIDTH]
            y = stats[i, cv2.CC_STAT_TOP]  # disparity ê°’
            h = stats[i, cv2.CC_STAT_HEIGHT]
            
            # í‰ê·  ì‹œì°¨
            avg_disp = y + h // 2
            
            obstacles.append({
                'x_range': (x, x + w),
                'disparity_range': (y, y + h),
                'avg_disparity': avg_disp,
                'width': w
            })
        
        return obstacles
```

---

## 4. ìœ„í—˜ ì˜ì—­ ë¶„ë¥˜

### 4.1 ì˜ì—­ ê´€ë¦¬ì

```python
"""
zone_manager.py
ìœ„í—˜ ì˜ì—­ ê´€ë¦¬
"""

import cv2
import numpy as np
from typing import List, Dict, Optional, Tuple
from dataclasses import dataclass
from enum import Enum


class ZoneType(Enum):
    """ì˜ì—­ íƒ€ì…"""
    FULL_SCREEN = 0     # ì „ì²´ í™”ë©´
    CENTER = 1          # ì¤‘ì•™ ì˜ì—­
    LEFT = 2            # ì™¼ìª½
    RIGHT = 3           # ì˜¤ë¥¸ìª½
    BOTTOM = 4          # í•˜ë‹¨
    CUSTOM = 5          # ì‚¬ìš©ì ì •ì˜


@dataclass
class DetectionZone:
    """ê°ì§€ ì˜ì—­"""
    name: str
    zone_type: ZoneType
    mask: np.ndarray
    priority: int = 1
    enabled: bool = True
    color: Tuple[int, int, int] = (0, 255, 0)


class ZoneManager:
    """ê°ì§€ ì˜ì—­ ê´€ë¦¬ì"""
    
    def __init__(self, image_size: Tuple[int, int]):
        """
        Parameters:
        - image_size: (width, height)
        """
        
        self.width, self.height = image_size
        self.zones: Dict[str, DetectionZone] = {}
        
        # ê¸°ë³¸ ì˜ì—­ ìƒì„±
        self._create_default_zones()
    
    def _create_default_zones(self):
        """ê¸°ë³¸ ì˜ì—­ ìƒì„±"""
        
        h, w = self.height, self.width
        
        # 1. ì¤‘ì•™ ì˜ì—­ (60%)
        center_mask = np.zeros((h, w), dtype=np.uint8)
        x1 = int(w * 0.2)
        x2 = int(w * 0.8)
        y1 = int(h * 0.2)
        y2 = int(h * 0.9)
        center_mask[y1:y2, x1:x2] = 255
        
        self.zones['center'] = DetectionZone(
            name='Center',
            zone_type=ZoneType.CENTER,
            mask=center_mask,
            priority=3,
            color=(0, 255, 255)
        )
        
        # 2. ì™¼ìª½ ì˜ì—­
        left_mask = np.zeros((h, w), dtype=np.uint8)
        left_mask[:, :int(w * 0.3)] = 255
        
        self.zones['left'] = DetectionZone(
            name='Left',
            zone_type=ZoneType.LEFT,
            mask=left_mask,
            priority=2,
            color=(255, 0, 0)
        )
        
        # 3. ì˜¤ë¥¸ìª½ ì˜ì—­
        right_mask = np.zeros((h, w), dtype=np.uint8)
        right_mask[:, int(w * 0.7):] = 255
        
        self.zones['right'] = DetectionZone(
            name='Right',
            zone_type=ZoneType.RIGHT,
            mask=right_mask,
            priority=2,
            color=(0, 0, 255)
        )
        
        # 4. í•˜ë‹¨ ì˜ì—­ (ì§€ë©´ ê·¼ì²˜)
        bottom_mask = np.zeros((h, w), dtype=np.uint8)
        bottom_mask[int(h * 0.7):, :] = 255
        
        self.zones['bottom'] = DetectionZone(
            name='Bottom',
            zone_type=ZoneType.BOTTOM,
            mask=bottom_mask,
            priority=1,
            color=(0, 255, 0)
        )
    
    def add_custom_zone(self, name: str, 
                        points: List[Tuple[int, int]],
                        priority: int = 1,
                        color: Tuple[int, int, int] = (255, 255, 0)):
        """
        ì‚¬ìš©ì ì •ì˜ ë‹¤ê°í˜• ì˜ì—­ ì¶”ê°€
        
        Parameters:
        - name: ì˜ì—­ ì´ë¦„
        - points: ë‹¤ê°í˜• ê¼­ì§€ì  [(x1,y1), (x2,y2), ...]
        - priority: ìš°ì„ ìˆœìœ„ (ë†’ì„ìˆ˜ë¡ ì¤‘ìš”)
        """
        
        mask = np.zeros((self.height, self.width), dtype=np.uint8)
        pts = np.array(points, dtype=np.int32)
        cv2.fillPoly(mask, [pts], 255)
        
        self.zones[name] = DetectionZone(
            name=name,
            zone_type=ZoneType.CUSTOM,
            mask=mask,
            priority=priority,
            color=color
        )
    
    def add_trapezoid_zone(self, name: str,
                           top_width_ratio: float = 0.3,
                           bottom_width_ratio: float = 0.8,
                           height_ratio: float = 0.6,
                           priority: int = 3):
        """
        ì‚¬ë‹¤ë¦¬ê¼´ ì˜ì—­ ì¶”ê°€ (ì „ë°© ê°ì§€ìš©)
        
        ì›ê·¼ê°ì„ ë°˜ì˜í•œ í˜•íƒœ
        """
        
        h, w = self.height, self.width
        
        top_w = int(w * top_width_ratio)
        bottom_w = int(w * bottom_width_ratio)
        zone_h = int(h * height_ratio)
        
        top_x1 = (w - top_w) // 2
        top_x2 = top_x1 + top_w
        bottom_x1 = (w - bottom_w) // 2
        bottom_x2 = bottom_x1 + bottom_w
        
        top_y = h - zone_h
        bottom_y = h
        
        points = [
            (top_x1, top_y),
            (top_x2, top_y),
            (bottom_x2, bottom_y),
            (bottom_x1, bottom_y)
        ]
        
        self.add_custom_zone(name, points, priority, (255, 255, 0))
    
    def get_zone(self, name: str) -> Optional[DetectionZone]:
        """ì˜ì—­ ë°˜í™˜"""
        return self.zones.get(name)
    
    def get_enabled_zones(self) -> List[DetectionZone]:
        """í™œì„±í™”ëœ ì˜ì—­ ë°˜í™˜ (ìš°ì„ ìˆœìœ„ ìˆœ)"""
        enabled = [z for z in self.zones.values() if z.enabled]
        return sorted(enabled, key=lambda z: z.priority, reverse=True)
    
    def enable_zone(self, name: str, enabled: bool = True):
        """ì˜ì—­ í™œì„±í™”/ë¹„í™œì„±í™”"""
        if name in self.zones:
            self.zones[name].enabled = enabled
    
    def get_combined_mask(self) -> np.ndarray:
        """ëª¨ë“  í™œì„±í™” ì˜ì—­ì˜ í•©ì§‘í•© ë§ˆìŠ¤í¬"""
        
        combined = np.zeros((self.height, self.width), dtype=np.uint8)
        
        for zone in self.get_enabled_zones():
            combined = cv2.bitwise_or(combined, zone.mask)
        
        return combined
    
    def visualize_zones(self, image: np.ndarray,
                        alpha: float = 0.3) -> np.ndarray:
        """ì˜ì—­ ì‹œê°í™”"""
        
        overlay = image.copy()
        
        for zone in self.get_enabled_zones():
            color_mask = np.zeros_like(image)
            color_mask[zone.mask > 0] = zone.color
            
            cv2.addWeighted(color_mask, alpha, overlay, 1, 0, overlay)
            
            # ì˜ì—­ ì´ë¦„ í‘œì‹œ
            moments = cv2.moments(zone.mask)
            if moments['m00'] > 0:
                cx = int(moments['m10'] / moments['m00'])
                cy = int(moments['m01'] / moments['m00'])
                cv2.putText(overlay, zone.name, (cx - 30, cy),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
        
        return overlay
```

---

## 5. ê²½ê³  ì‹œìŠ¤í…œ

### 5.1 ê²½ê³  ê´€ë¦¬ì

```python
"""
alert_system.py
ê²½ê³  ì‹œìŠ¤í…œ
"""

import time
import threading
from typing import Optional, Callable
from enum import Enum
from dataclasses import dataclass
import numpy as np

# ì‚¬ìš´ë“œ ì¬ìƒ (ì„ íƒ)
try:
    import pygame
    pygame.mixer.init()
    SOUND_AVAILABLE = True
except ImportError:
    SOUND_AVAILABLE = False


class AlertType(Enum):
    """ê²½ê³  íƒ€ì…"""
    VISUAL = 1      # ì‹œê°ì 
    AUDIO = 2       # ì²­ê°ì 
    HAPTIC = 3      # ì´‰ê°ì  (í™•ì¥ìš©)
    ALL = 4         # ëª¨ë“  íƒ€ì…


@dataclass
class AlertConfig:
    """ê²½ê³  ì„¤ì •"""
    enabled: bool = True
    visual: bool = True
    audio: bool = True
    min_interval_ms: int = 500  # ìµœì†Œ ê²½ê³  ê°„ê²©


class AlertSystem:
    """ê²½ê³  ì‹œìŠ¤í…œ"""
    
    def __init__(self, config: AlertConfig = None):
        self.config = config or AlertConfig()
        
        # ë§ˆì§€ë§‰ ê²½ê³  ì‹œê°„
        self.last_alert_time = {}
        
        # ì½œë°± í•¨ìˆ˜
        self.alert_callbacks = []
        
        # ì‚¬ìš´ë“œ íŒŒì¼ (ìœ„í—˜ ìˆ˜ì¤€ë³„)
        self.sounds = {}
        if SOUND_AVAILABLE and self.config.audio:
            self._load_sounds()
        
        # ì‹œê°ì  ê²½ê³  ìƒ‰ìƒ
        self.alert_colors = {
            'SAFE': (0, 255, 0),       # ë…¹ìƒ‰
            'CAUTION': (0, 255, 255),  # ë…¸ë€ìƒ‰
            'WARNING': (0, 165, 255),  # ì£¼í™©ìƒ‰
            'DANGER': (0, 0, 255),     # ë¹¨ê°„ìƒ‰
            'CRITICAL': (0, 0, 255),   # ë¹¨ê°„ìƒ‰ (ê¹œë¹¡ì„)
        }
    
    def _load_sounds(self):
        """ê²½ê³ ìŒ ë¡œë“œ"""
        
        sound_files = {
            'CAUTION': 'assets/sounds/warning_low.wav',
            'WARNING': 'assets/sounds/warning_medium.wav',
            'DANGER': 'assets/sounds/warning_high.wav',
            'CRITICAL': 'assets/sounds/warning_high.wav',
        }
        
        for level, filepath in sound_files.items():
            try:
                self.sounds[level] = pygame.mixer.Sound(filepath)
            except:
                pass
    
    def add_callback(self, callback: Callable):
        """ê²½ê³  ì½œë°± ì¶”ê°€"""
        self.alert_callbacks.append(callback)
    
    def trigger_alert(self, danger_level: str, 
                      distance_mm: float,
                      source: str = "obstacle"):
        """
        ê²½ê³  ë°œìƒ
        
        Parameters:
        - danger_level: ìœ„í—˜ ìˆ˜ì¤€ ì´ë¦„
        - distance_mm: ê±°ë¦¬
        - source: ê²½ê³  ì†ŒìŠ¤
        """
        
        if not self.config.enabled:
            return
        
        # ìµœì†Œ ê°„ê²© ì²´í¬
        current_time = time.time() * 1000
        key = f"{danger_level}_{source}"
        
        if key in self.last_alert_time:
            elapsed = current_time - self.last_alert_time[key]
            if elapsed < self.config.min_interval_ms:
                return
        
        self.last_alert_time[key] = current_time
        
        # ì˜¤ë””ì˜¤ ê²½ê³ 
        if self.config.audio and danger_level in self.sounds:
            self._play_sound(danger_level)
        
        # ì½œë°± í˜¸ì¶œ
        for callback in self.alert_callbacks:
            callback(danger_level, distance_mm, source)
    
    def _play_sound(self, danger_level: str):
        """ê²½ê³ ìŒ ì¬ìƒ"""
        
        if SOUND_AVAILABLE and danger_level in self.sounds:
            try:
                self.sounds[danger_level].play()
            except:
                pass
    
    def get_alert_color(self, danger_level: str) -> tuple:
        """ìœ„í—˜ ìˆ˜ì¤€ì— ë”°ë¥¸ ìƒ‰ìƒ ë°˜í™˜"""
        return self.alert_colors.get(danger_level, (255, 255, 255))
    
    def create_visual_alert(self, image: np.ndarray,
                            danger_level: str,
                            distance_mm: float) -> np.ndarray:
        """
        ì‹œê°ì  ê²½ê³  ì˜¤ë²„ë ˆì´
        
        Returns:
        - image: ê²½ê³ ê°€ ì¶”ê°€ëœ ì´ë¯¸ì§€
        """
        
        h, w = image.shape[:2]
        color = self.get_alert_color(danger_level)
        
        # í…Œë‘ë¦¬ íš¨ê³¼
        border_width = 10
        
        if danger_level == 'CRITICAL':
            # ê¹œë¹¡ì„ íš¨ê³¼
            if int(time.time() * 4) % 2 == 0:
                cv2.rectangle(image, (0, 0), (w-1, h-1), color, border_width)
        elif danger_level in ['DANGER', 'WARNING']:
            cv2.rectangle(image, (0, 0), (w-1, h-1), color, border_width)
        
        # ê²½ê³  í…ìŠ¤íŠ¸
        text = f"WARNING: {danger_level} - {distance_mm/1000:.1f}m"
        
        # ë°°ê²½
        (text_w, text_h), _ = cv2.getTextSize(
            text, cv2.FONT_HERSHEY_SIMPLEX, 1, 2
        )
        
        cv2.rectangle(image, (w//2 - text_w//2 - 10, 20),
                     (w//2 + text_w//2 + 10, 60), (0, 0, 0), -1)
        
        cv2.putText(image, text, (w//2 - text_w//2, 50),
                   cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)
        
        return image
    
    def create_distance_bar(self, image: np.ndarray,
                            distance_mm: float,
                            max_distance: float = 5000) -> np.ndarray:
        """
        ê±°ë¦¬ ë°” í‘œì‹œ
        
        ì‹œê°ì  ê±°ë¦¬ ê²Œì´ì§€
        """
        
        h, w = image.shape[:2]
        
        bar_width = 30
        bar_height = h - 100
        bar_x = w - 50
        bar_y = 50
        
        # ë°°ê²½
        cv2.rectangle(image, (bar_x, bar_y), 
                     (bar_x + bar_width, bar_y + bar_height),
                     (50, 50, 50), -1)
        
        # ê±°ë¦¬ë³„ ìƒ‰ìƒ ì˜ì—­
        segments = [
            (0.0, 0.1, (0, 0, 255)),      # CRITICAL
            (0.1, 0.2, (0, 0, 255)),      # DANGER
            (0.2, 0.4, (0, 165, 255)),    # WARNING
            (0.4, 0.6, (0, 255, 255)),    # CAUTION
            (0.6, 1.0, (0, 255, 0)),      # SAFE
        ]
        
        for start_ratio, end_ratio, color in segments:
            y1 = bar_y + int(bar_height * (1 - end_ratio))
            y2 = bar_y + int(bar_height * (1 - start_ratio))
            cv2.rectangle(image, (bar_x, y1), (bar_x + bar_width, y2), color, -1)
        
        # í˜„ì¬ ê±°ë¦¬ ë§ˆì»¤
        ratio = min(distance_mm / max_distance, 1.0)
        marker_y = bar_y + int(bar_height * (1 - ratio))
        
        cv2.line(image, (bar_x - 10, marker_y), 
                (bar_x + bar_width + 10, marker_y), (255, 255, 255), 3)
        
        # ê±°ë¦¬ í…ìŠ¤íŠ¸
        cv2.putText(image, f"{distance_mm/1000:.1f}m", 
                   (bar_x - 50, marker_y + 5),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
        
        return image
```

---

## 6. ì˜ì—­ ë¶„í• 

### 6.1 ì‹œë§¨í‹± ë¶„í•  (ì˜µì…˜)

```python
"""
segmentation.py
ê¹Šì´ ê¸°ë°˜ ì˜ì—­ ë¶„í• 
"""

import cv2
import numpy as np
from typing import Tuple, List


class DepthSegmentation:
    """ê¹Šì´ ê¸°ë°˜ ì˜ì—­ ë¶„í• """
    
    def __init__(self, num_layers: int = 5):
        """
        Parameters:
        - num_layers: ë¶„í•  ë ˆì´ì–´ ìˆ˜
        """
        self.num_layers = num_layers
    
    def segment_by_distance(self, depth: np.ndarray,
                            distance_ranges: List[Tuple[float, float]]) -> np.ndarray:
        """
        ê±°ë¦¬ ë²”ìœ„ë³„ ë¶„í• 
        
        Parameters:
        - depth: ê¹Šì´ ë§µ (mm)
        - distance_ranges: [(min1, max1), (min2, max2), ...]
        
        Returns:
        - labels: ë ˆì´ë¸” ë§µ (0 = ë°°ê²½, 1, 2, 3, ...)
        """
        
        labels = np.zeros(depth.shape, dtype=np.uint8)
        
        for i, (d_min, d_max) in enumerate(distance_ranges, 1):
            mask = (depth >= d_min) & (depth < d_max)
            labels[mask] = i
        
        return labels
    
    def segment_equal_depth(self, depth: np.ndarray,
                            min_depth: float = 500,
                            max_depth: float = 5000) -> np.ndarray:
        """
        ê· ë“± ê±°ë¦¬ ë¶„í• 
        
        Returns:
        - labels: ë ˆì´ë¸” ë§µ
        """
        
        # ê±°ë¦¬ ë²”ìœ„ ìƒì„±
        ranges = []
        step = (max_depth - min_depth) / self.num_layers
        
        for i in range(self.num_layers):
            d_min = min_depth + i * step
            d_max = min_depth + (i + 1) * step
            ranges.append((d_min, d_max))
        
        return self.segment_by_distance(depth, ranges)
    
    def colorize_segments(self, labels: np.ndarray) -> np.ndarray:
        """ë¶„í•  ê²°ê³¼ ì»¬ëŸ¬í™”"""
        
        # ìƒ‰ìƒ ë§µ
        colors = [
            (0, 0, 0),        # ë°°ê²½
            (0, 0, 255),      # ê°€ì¥ ê°€ê¹Œì›€ (ë¹¨ê°•)
            (0, 128, 255),    # ì£¼í™©
            (0, 255, 255),    # ë…¸ë‘
            (0, 255, 0),      # ì´ˆë¡
            (255, 255, 0),    # ì²­ë¡
            (255, 0, 0),      # íŒŒë‘
        ]
        
        colored = np.zeros((*labels.shape, 3), dtype=np.uint8)
        
        for i, color in enumerate(colors[:self.num_layers + 1]):
            colored[labels == i] = color
        
        return colored
    
    def get_free_space(self, depth: np.ndarray,
                       safe_distance: float = 2000) -> np.ndarray:
        """
        ì´ë™ ê°€ëŠ¥ ì˜ì—­ (Free Space) ì¶”ì¶œ
        
        Returns:
        - free_mask: ì•ˆì „ ì˜ì—­ ë§ˆìŠ¤í¬
        """
        
        # ì•ˆì „ ê±°ë¦¬ ì´ìƒì´ê±°ë‚˜ ìœ íš¨í•˜ì§€ ì•Šì€ ì˜ì—­
        free_mask = (depth > safe_distance) | (depth <= 0)
        
        # ë…¸ì´ì¦ˆ ì œê±°
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))
        free_mask = cv2.morphologyEx(free_mask.astype(np.uint8), 
                                      cv2.MORPH_OPEN, kernel)
        
        return free_mask.astype(bool)


class OccupancyGrid:
    """ì ìœ  ê·¸ë¦¬ë“œ ë§µ"""
    
    def __init__(self, grid_size: Tuple[int, int] = (100, 100),
                 cell_size_mm: float = 50):
        """
        Parameters:
        - grid_size: ê·¸ë¦¬ë“œ í¬ê¸° (width, height)
        - cell_size_mm: ì…€ í¬ê¸° (mm)
        """
        
        self.grid_size = grid_size
        self.cell_size = cell_size_mm
        
        # ê·¸ë¦¬ë“œ ì´ˆê¸°í™” (0.5 = ë¯¸ì§€, 0 = ë¹„ì–´ìˆìŒ, 1 = ì ìœ )
        self.grid = np.full(grid_size, 0.5, dtype=np.float32)
    
    def update_from_depth(self, depth: np.ndarray,
                          camera_params: dict):
        """
        ê¹Šì´ ë§µì—ì„œ ì ìœ  ê·¸ë¦¬ë“œ ì—…ë°ì´íŠ¸
        
        Parameters:
        - depth: ê¹Šì´ ë§µ
        - camera_params: ì¹´ë©”ë¼ íŒŒë¼ë¯¸í„° (fx, fy, cx, cy)
        """
        
        h, w = depth.shape
        fx = camera_params['fx']
        cx = camera_params['cx']
        
        # ê·¸ë¦¬ë“œ ì¤‘ì‹¬
        grid_cx = self.grid_size[0] // 2
        grid_cy = self.grid_size[1] // 2
        
        # ê° ì—´ì— ëŒ€í•´ ì²˜ë¦¬
        for col in range(w):
            # í•´ë‹¹ ì—´ì˜ ìœ íš¨í•œ ê¹Šì´
            column = depth[:, col]
            valid_idx = np.where(column > 0)[0]
            
            if len(valid_idx) == 0:
                continue
            
            # ìµœì†Œ ê¹Šì´ (ê°€ì¥ ê°€ê¹Œìš´ ì¥ì• ë¬¼)
            min_depth = column[valid_idx].min()
            
            # ì¹´ë©”ë¼ ì¢Œí‘œê³„ì—ì„œ X ê³„ì‚°
            x_camera = (col - cx) * min_depth / fx
            
            # ê·¸ë¦¬ë“œ ì¢Œí‘œ ë³€í™˜
            grid_x = int(grid_cx + x_camera / self.cell_size)
            grid_y = int(grid_cy - min_depth / self.cell_size)  # YëŠ” ë°˜ì „
            
            # ë²”ìœ„ ì²´í¬
            if 0 <= grid_x < self.grid_size[0] and 0 <= grid_y < self.grid_size[1]:
                # ì ìœ  ë§ˆí‚¹
                self.grid[grid_y, grid_x] = 1.0
                
                # ì¹´ë©”ë¼ì™€ ì  ì‚¬ì´ëŠ” ë¹„ì–´ìˆìŒ
                # (ê°„ë‹¨í•œ ray casting)
                for gy in range(grid_cy, grid_y):
                    if 0 <= gy < self.grid_size[1]:
                        self.grid[gy, grid_x] = max(0, self.grid[gy, grid_x] - 0.1)
    
    def get_occupancy_image(self) -> np.ndarray:
        """ì ìœ  ê·¸ë¦¬ë“œ ì‹œê°í™”"""
        
        # 0=í°ìƒ‰(ë¹„ì–´ìˆìŒ), 0.5=íšŒìƒ‰(ë¯¸ì§€), 1=ê²€ì •(ì ìœ )
        img = ((1 - self.grid) * 255).astype(np.uint8)
        img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)
        
        # ì¹´ë©”ë¼ ìœ„ì¹˜ í‘œì‹œ
        cx, cy = self.grid_size[0] // 2, self.grid_size[1] // 2
        cv2.circle(img, (cx, cy), 3, (0, 0, 255), -1)
        
        return img
    
    def clear(self):
        """ê·¸ë¦¬ë“œ ì´ˆê¸°í™”"""
        self.grid.fill(0.5)
```

---

## 7. ì¶”ì  ë° ì˜ˆì¸¡

### 7.1 ê°„ë‹¨í•œ ê°ì²´ ì¶”ì ê¸°

```python
"""
object_tracker.py
ì¥ì• ë¬¼ ì¶”ì 
"""

import numpy as np
from typing import List, Dict, Optional, Tuple
from dataclasses import dataclass, field
from collections import deque


@dataclass
class TrackedObject:
    """ì¶”ì  ì¤‘ì¸ ê°ì²´"""
    id: int
    positions: deque = field(default_factory=lambda: deque(maxlen=30))
    distances: deque = field(default_factory=lambda: deque(maxlen=30))
    last_seen: int = 0
    lost_frames: int = 0
    velocity: Tuple[float, float] = (0, 0)
    approaching: bool = False
    
    def update(self, center: Tuple[int, int], distance: float, frame_id: int):
        """ìƒíƒœ ì—…ë°ì´íŠ¸"""
        self.positions.append(center)
        self.distances.append(distance)
        self.last_seen = frame_id
        self.lost_frames = 0
        
        # ì†ë„ ê³„ì‚°
        if len(self.positions) >= 2:
            dx = center[0] - self.positions[-2][0]
            dy = center[1] - self.positions[-2][1]
            self.velocity = (dx, dy)
        
        # ì ‘ê·¼ ì—¬ë¶€
        if len(self.distances) >= 2:
            self.approaching = self.distances[-1] < self.distances[-2]
    
    def predict_position(self, frames_ahead: int = 5) -> Tuple[int, int]:
        """ìœ„ì¹˜ ì˜ˆì¸¡"""
        if len(self.positions) == 0:
            return (0, 0)
        
        last_pos = self.positions[-1]
        vx, vy = self.velocity
        
        pred_x = int(last_pos[0] + vx * frames_ahead)
        pred_y = int(last_pos[1] + vy * frames_ahead)
        
        return (pred_x, pred_y)
    
    def get_approach_rate(self) -> float:
        """ì ‘ê·¼ ì†ë„ (mm/frame)"""
        if len(self.distances) < 2:
            return 0
        
        return self.distances[-2] - self.distances[-1]
    
    def estimate_time_to_collision(self) -> Optional[float]:
        """ì¶©ëŒê¹Œì§€ ì˜ˆìƒ ì‹œê°„ (í”„ë ˆì„)"""
        rate = self.get_approach_rate()
        
        if rate <= 0:
            return None  # ë©€ì–´ì§€ê±°ë‚˜ ì •ì§€
        
        if len(self.distances) == 0:
            return None
        
        current_distance = self.distances[-1]
        
        return current_distance / rate


class SimpleTracker:
    """ê°„ë‹¨í•œ ì¥ì• ë¬¼ ì¶”ì ê¸° (IOU ê¸°ë°˜)"""
    
    def __init__(self, max_lost_frames: int = 10,
                 iou_threshold: float = 0.3):
        """
        Parameters:
        - max_lost_frames: ì¶”ì  ìœ ì§€ ìµœëŒ€ ì†ì‹¤ í”„ë ˆì„
        - iou_threshold: ë§¤ì¹­ IOU ì„ê³„ê°’
        """
        
        self.max_lost_frames = max_lost_frames
        self.iou_threshold = iou_threshold
        
        self.tracked_objects: Dict[int, TrackedObject] = {}
        self.next_id = 0
        self.frame_count = 0
    
    def update(self, detections: List[dict]) -> List[TrackedObject]:
        """
        ì¶”ì  ì—…ë°ì´íŠ¸
        
        Parameters:
        - detections: [{'bbox': (x,y,w,h), 'center': (cx,cy), 'distance': d}, ...]
        
        Returns:
        - tracked_objects: ì¶”ì  ì¤‘ì¸ ê°ì²´ ë¦¬ìŠ¤íŠ¸
        """
        
        self.frame_count += 1
        
        if len(detections) == 0:
            # ëª¨ë“  ì¶”ì  ê°ì²´ ì†ì‹¤ ì¹´ìš´íŠ¸ ì¦ê°€
            for obj in self.tracked_objects.values():
                obj.lost_frames += 1
            
            # ì˜¤ë˜ëœ ì¶”ì  ì œê±°
            self._remove_lost_tracks()
            return list(self.tracked_objects.values())
        
        # í˜„ì¬ ì¶”ì ê³¼ ê°ì§€ ë§¤ì¹­
        matched, unmatched_dets, unmatched_tracks = self._match_detections(detections)
        
        # ë§¤ì¹­ëœ ì¶”ì  ì—…ë°ì´íŠ¸
        for det_idx, track_id in matched:
            det = detections[det_idx]
            self.tracked_objects[track_id].update(
                det['center'], det['distance'], self.frame_count
            )
        
        # ìƒˆ ì¶”ì  ìƒì„±
        for det_idx in unmatched_dets:
            det = detections[det_idx]
            new_track = TrackedObject(id=self.next_id)
            new_track.update(det['center'], det['distance'], self.frame_count)
            self.tracked_objects[self.next_id] = new_track
            self.next_id += 1
        
        # ì†ì‹¤ëœ ì¶”ì  ì¹´ìš´íŠ¸ ì¦ê°€
        for track_id in unmatched_tracks:
            self.tracked_objects[track_id].lost_frames += 1
        
        # ì˜¤ë˜ëœ ì¶”ì  ì œê±°
        self._remove_lost_tracks()
        
        return list(self.tracked_objects.values())
    
    def _match_detections(self, detections: List[dict]) -> Tuple[List, List, List]:
        """ê°ì§€ì™€ ì¶”ì  ë§¤ì¹­"""
        
        if len(self.tracked_objects) == 0:
            return [], list(range(len(detections))), []
        
        track_ids = list(self.tracked_objects.keys())
        
        # ê±°ë¦¬ í–‰ë ¬ ê³„ì‚°
        cost_matrix = np.zeros((len(detections), len(track_ids)))
        
        for i, det in enumerate(detections):
            for j, track_id in enumerate(track_ids):
                track = self.tracked_objects[track_id]
                if len(track.positions) > 0:
                    last_pos = track.positions[-1]
                    # ìœ í´ë¦¬ë“œ ê±°ë¦¬
                    dist = np.sqrt(
                        (det['center'][0] - last_pos[0])**2 +
                        (det['center'][1] - last_pos[1])**2
                    )
                    cost_matrix[i, j] = dist
                else:
                    cost_matrix[i, j] = 1e6
        
        # ê·¸ë¦¬ë”” ë§¤ì¹­
        matched = []
        unmatched_dets = list(range(len(detections)))
        unmatched_tracks = list(track_ids)
        
        while len(unmatched_dets) > 0 and len(unmatched_tracks) > 0:
            # ìµœì†Œ ë¹„ìš© ì°¾ê¸°
            min_cost = np.inf
            min_i, min_j = -1, -1
            
            for i in unmatched_dets:
                for j_idx, j in enumerate(unmatched_tracks):
                    if cost_matrix[i, track_ids.index(j)] < min_cost:
                        min_cost = cost_matrix[i, track_ids.index(j)]
                        min_i, min_j = i, j
            
            # ì„ê³„ê°’ ì²´í¬
            if min_cost > 100:  # í”½ì…€ ê±°ë¦¬ ì„ê³„ê°’
                break
            
            matched.append((min_i, min_j))
            unmatched_dets.remove(min_i)
            unmatched_tracks.remove(min_j)
        
        return matched, unmatched_dets, unmatched_tracks
    
    def _remove_lost_tracks(self):
        """ì†ì‹¤ëœ ì¶”ì  ì œê±°"""
        to_remove = [
            track_id for track_id, track in self.tracked_objects.items()
            if track.lost_frames > self.max_lost_frames
        ]
        
        for track_id in to_remove:
            del self.tracked_objects[track_id]
    
    def get_approaching_objects(self) -> List[TrackedObject]:
        """ì ‘ê·¼ ì¤‘ì¸ ê°ì²´ ë°˜í™˜"""
        return [obj for obj in self.tracked_objects.values() if obj.approaching]
    
    def get_collision_warnings(self, threshold_frames: float = 30) -> List[TrackedObject]:
        """ì¶©ëŒ ê²½ê³  ê°ì²´ ë°˜í™˜"""
        warnings = []
        
        for obj in self.tracked_objects.values():
            ttc = obj.estimate_time_to_collision()
            if ttc is not None and ttc < threshold_frames:
                warnings.append(obj)
        
        return warnings
```

---

## 8. GUI êµ¬í˜„

### 8.1 ì¥ì• ë¬¼ ê°ì§€ GUI

```python
"""
gui.py
ì¥ì• ë¬¼ ê°ì§€ ì‹œìŠ¤í…œ GUI
"""

import cv2
import numpy as np
from typing import List, Optional, Tuple
import time


class ObstacleDetectionGUI:
    """ì¥ì• ë¬¼ ê°ì§€ GUI"""
    
    def __init__(self, window_name: str = "Obstacle Detection"):
        self.window_name = window_name
        
        # í‘œì‹œ ì„¤ì •
        self.show_depth = True
        self.show_zones = True
        self.show_bboxes = True
        self.show_tracks = True
        self.show_grid = False
        
        # ìƒ‰ìƒ
        self.danger_colors = {
            'SAFE': (0, 255, 0),
            'CAUTION': (0, 255, 255),
            'WARNING': (0, 165, 255),
            'DANGER': (0, 0, 255),
            'CRITICAL': (0, 0, 255),
        }
        
        # FPS
        self.fps_history = []
        self.last_time = time.time()
        
        cv2.namedWindow(self.window_name, cv2.WINDOW_NORMAL)
    
    def update_fps(self) -> float:
        """FPS ì—…ë°ì´íŠ¸"""
        current = time.time()
        fps = 1.0 / (current - self.last_time + 1e-6)
        self.last_time = current
        
        self.fps_history.append(fps)
        if len(self.fps_history) > 30:
            self.fps_history.pop(0)
        
        return np.mean(self.fps_history)
    
    def draw_obstacle(self, image: np.ndarray, obstacle, 
                      show_info: bool = True):
        """ì¥ì• ë¬¼ í‘œì‹œ"""
        
        x, y, w, h = obstacle.bbox
        color = self.danger_colors.get(obstacle.danger_level.name, (255, 255, 255))
        
        # ë°”ìš´ë”© ë°•ìŠ¤
        cv2.rectangle(image, (x, y), (x + w, y + h), color, 2)
        
        # ì¤‘ì‹¬ì 
        cx, cy = obstacle.center
        cv2.circle(image, (cx, cy), 5, color, -1)
        
        # ì •ë³´ í‘œì‹œ
        if show_info:
            distance_m = obstacle.distance_mm / 1000
            text = f"{obstacle.danger_level.name}: {distance_m:.1f}m"
            
            # ë°°ê²½
            (text_w, text_h), _ = cv2.getTextSize(
                text, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1
            )
            cv2.rectangle(image, (x, y - text_h - 5), 
                         (x + text_w, y), color, -1)
            
            cv2.putText(image, text, (x, y - 5),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1)
    
    def draw_track(self, image: np.ndarray, track, 
                   show_prediction: bool = True):
        """ì¶”ì  ê²½ë¡œ í‘œì‹œ"""
        
        if len(track.positions) < 2:
            return
        
        # ê²½ë¡œ ì„ 
        points = list(track.positions)
        for i in range(1, len(points)):
            alpha = i / len(points)
            color = (
                int(255 * alpha),
                int(255 * (1 - alpha)),
                0
            )
            cv2.line(image, points[i-1], points[i], color, 2)
        
        # ì˜ˆì¸¡ ìœ„ì¹˜
        if show_prediction and track.approaching:
            pred_pos = track.predict_position(10)
            cv2.circle(image, pred_pos, 8, (0, 255, 255), 2)
            cv2.line(image, points[-1], pred_pos, (0, 255, 255), 1)
    
    def draw_info_panel(self, image: np.ndarray,
                        num_obstacles: int,
                        closest_distance: float,
                        danger_level: str,
                        fps: float):
        """ì •ë³´ íŒ¨ë„"""
        
        h, w = image.shape[:2]
        
        # ë°˜íˆ¬ëª… ë°°ê²½
        overlay = image.copy()
        cv2.rectangle(overlay, (10, 10), (280, 140), (0, 0, 0), -1)
        cv2.addWeighted(overlay, 0.6, image, 0.4, 0, image)
        
        # í…ìŠ¤íŠ¸
        y = 35
        cv2.putText(image, f"FPS: {fps:.1f}", (20, y),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
        
        y += 25
        cv2.putText(image, f"Obstacles: {num_obstacles}", (20, y),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        
        y += 25
        color = self.danger_colors.get(danger_level, (255, 255, 255))
        cv2.putText(image, f"Level: {danger_level}", (20, y),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)
        
        y += 25
        if closest_distance > 0:
            cv2.putText(image, f"Closest: {closest_distance/1000:.2f}m", (20, y),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)
        else:
            cv2.putText(image, "Closest: --", (20, y),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (128, 128, 128), 2)
    
    def draw_minimap(self, image: np.ndarray,
                     obstacles: list,
                     max_distance: float = 5000):
        """ë¯¸ë‹ˆë§µ (íƒ‘ë·°)"""
        
        h, w = image.shape[:2]
        
        map_size = 150
        map_x = w - map_size - 20
        map_y = h - map_size - 20
        
        # ë°°ê²½
        cv2.rectangle(image, (map_x, map_y), 
                     (map_x + map_size, map_y + map_size),
                     (30, 30, 30), -1)
        
        # ê±°ë¦¬ ì›
        center = (map_x + map_size // 2, map_y + map_size)
        for dist_m in [1, 2, 3, 4, 5]:
            radius = int((dist_m / (max_distance / 1000)) * map_size)
            cv2.ellipse(image, center, (radius, radius // 2), 0, 
                       180, 360, (60, 60, 60), 1)
        
        # ì¥ì• ë¬¼ í‘œì‹œ
        for obs in obstacles:
            # ê°„ë‹¨í•œ ì¢Œí‘œ ë³€í™˜ (XëŠ” ê°€ë¡œ, ZëŠ” ì„¸ë¡œ)
            rel_x = (obs.center[0] - w // 2) / w  # -0.5 ~ 0.5
            rel_z = obs.distance_mm / max_distance  # 0 ~ 1
            
            px = int(center[0] + rel_x * map_size)
            py = int(center[1] - rel_z * map_size)
            
            color = self.danger_colors.get(obs.danger_level.name, (255, 255, 255))
            cv2.circle(image, (px, py), 5, color, -1)
        
        # ì¹´ë©”ë¼ ìœ„ì¹˜ (ì‚¼ê°í˜•)
        pts = np.array([
            [center[0], center[1] - 5],
            [center[0] - 5, center[1] + 5],
            [center[0] + 5, center[1] + 5]
        ], np.int32)
        cv2.fillPoly(image, [pts], (0, 255, 0))
    
    def colorize_depth(self, depth: np.ndarray,
                       max_depth: float = 5000) -> np.ndarray:
        """ê¹Šì´ ë§µ ì»¬ëŸ¬í™”"""
        
        depth_clipped = np.clip(depth, 0, max_depth)
        depth_norm = (1 - depth_clipped / max_depth) * 255
        depth_color = cv2.applyColorMap(depth_norm.astype(np.uint8), cv2.COLORMAP_TURBO)
        depth_color[depth <= 0] = [0, 0, 0]
        
        return depth_color
    
    def render(self, color_image: np.ndarray,
               depth: np.ndarray,
               obstacles: list,
               tracks: list = None,
               zones=None) -> np.ndarray:
        """ì „ì²´ ë Œë”ë§"""
        
        fps = self.update_fps()
        display = color_image.copy()
        h, w = display.shape[:2]
        
        # ì˜ì—­ í‘œì‹œ
        if self.show_zones and zones is not None:
            display = zones.visualize_zones(display, alpha=0.2)
        
        # ì¥ì• ë¬¼ í‘œì‹œ
        if self.show_bboxes:
            for obs in obstacles:
                self.draw_obstacle(display, obs)
        
        # ì¶”ì  ê²½ë¡œ í‘œì‹œ
        if self.show_tracks and tracks:
            for track in tracks:
                self.draw_track(display, track)
        
        # ê°€ì¥ ê°€ê¹Œìš´ ì¥ì• ë¬¼
        closest_dist = 0
        danger_level = 'SAFE'
        if obstacles:
            closest = min(obstacles, key=lambda o: o.distance_mm)
            closest_dist = closest.distance_mm
            danger_level = closest.danger_level.name
        
        # ì •ë³´ íŒ¨ë„
        self.draw_info_panel(display, len(obstacles), closest_dist,
                            danger_level, fps)
        
        # ë¯¸ë‹ˆë§µ
        self.draw_minimap(display, obstacles)
        
        # ê¹Šì´ ë§µ (ì‘ì€ í¬ê¸°)
        if self.show_depth:
            depth_color = self.colorize_depth(depth)
            depth_small = cv2.resize(depth_color, (w // 4, h // 4))
            display[10:10 + h // 4, w - w // 4 - 10:w - 10] = depth_small
        
        return display
    
    def show(self, image: np.ndarray):
        """ì´ë¯¸ì§€ í‘œì‹œ"""
        cv2.imshow(self.window_name, image)
    
    def wait_key(self, delay: int = 1) -> int:
        """í‚¤ ì…ë ¥"""
        return cv2.waitKey(delay) & 0xFF
    
    def close(self):
        """ìœˆë„ìš° ë‹«ê¸°"""
        cv2.destroyAllWindows()
```

---

## 9. ì „ì²´ ì½”ë“œ

### 9.1 ë©”ì¸ ì‹¤í–‰ íŒŒì¼

```python
"""
main.py
ì¥ì• ë¬¼ ê°ì§€ ì‹œìŠ¤í…œ ë©”ì¸
"""

import argparse
import yaml
import cv2
import numpy as np
import sys
from datetime import datetime

# ë¡œì»¬ ëª¨ë“ˆ
sys.path.append('src')
from stereo_camera import StereoCamera
from depth_processor import DepthProcessor
from obstacle_detector import ObstacleDetector, DangerLevel
from zone_manager import ZoneManager
from alert_system import AlertSystem, AlertConfig
from object_tracker import SimpleTracker
from gui import ObstacleDetectionGUI


class ObstacleDetectionSystem:
    """ì¥ì• ë¬¼ ê°ì§€ ì‹œìŠ¤í…œ"""
    
    def __init__(self, config_file: str):
        # ì„¤ì • ë¡œë“œ
        with open(config_file, 'r') as f:
            self.config = yaml.safe_load(f)
        
        self._init_components()
        
        print("\n" + "="*60)
        print("ğŸš§ ì¥ì• ë¬¼ ê°ì§€ ì‹œìŠ¤í…œ")
        print("="*60)
    
    def _init_components(self):
        """ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”"""
        
        # ìŠ¤í…Œë ˆì˜¤ ì¹´ë©”ë¼
        self.camera = StereoCamera(
            calibration_file=self.config['calibration_file'],
            left_id=self.config['camera']['left_id'],
            right_id=self.config['camera']['right_id']
        )
        
        # ê¹Šì´ ì²˜ë¦¬ê¸°
        self.depth_processor = DepthProcessor(
            focal_length=self.camera.focal_length,
            baseline=self.camera.baseline,
            **self.config['stereo']
        )
        
        # ì¥ì• ë¬¼ ê°ì§€ê¸°
        self.detector = ObstacleDetector(self.config['detection'])
        
        # ì˜ì—­ ê´€ë¦¬ì
        img_size = (self.camera.width, self.camera.height)
        self.zone_manager = ZoneManager(img_size)
        self.zone_manager.add_trapezoid_zone('forward', priority=3)
        
        # ê²½ê³  ì‹œìŠ¤í…œ
        alert_config = AlertConfig(**self.config.get('alert', {}))
        self.alert_system = AlertSystem(alert_config)
        
        # ì¶”ì ê¸°
        self.tracker = SimpleTracker(
            max_lost_frames=self.config['tracking']['max_lost_frames'],
            iou_threshold=self.config['tracking']['iou_threshold']
        )
        
        # GUI
        self.gui = ObstacleDetectionGUI()
    
    def run(self):
        """ë©”ì¸ ë£¨í”„"""
        
        print("\nì¡°ì‘ ë°©ë²•:")
        print("  [D] - ê¹Šì´ë§µ í‘œì‹œ í† ê¸€")
        print("  [Z] - ì˜ì—­ í‘œì‹œ í† ê¸€")
        print("  [T] - ì¶”ì  í‘œì‹œ í† ê¸€")
        print("  [S] - ìŠ¤í¬ë¦°ìƒ·")
        print("  [Q] - ì¢…ë£Œ")
        print("="*60 + "\n")
        
        while True:
            # í”„ë ˆì„ ìº¡ì²˜
            rect_left, rect_right = self.camera.capture_rectified()
            
            if rect_left is None:
                continue
            
            # ê¹Šì´ ê³„ì‚°
            disparity, depth = self.depth_processor.compute(rect_left, rect_right)
            
            # ì¥ì• ë¬¼ ê°ì§€
            obstacles = self.detector.detect(depth, rect_left)
            
            # ì¶”ì  ì—…ë°ì´íŠ¸
            detections = [
                {
                    'bbox': o.bbox,
                    'center': o.center,
                    'distance': o.distance_mm
                }
                for o in obstacles
            ]
            tracks = self.tracker.update(detections)
            
            # ê²½ê³  ì²˜ë¦¬
            self._process_alerts(obstacles)
            
            # ë Œë”ë§
            display = self.gui.render(
                rect_left, depth, obstacles, tracks, self.zone_manager
            )
            
            # ê²½ê³  ì˜¤ë²„ë ˆì´
            if obstacles:
                closest = min(obstacles, key=lambda o: o.distance_mm)
                if closest.danger_level.value >= DangerLevel.WARNING.value:
                    display = self.alert_system.create_visual_alert(
                        display,
                        closest.danger_level.name,
                        closest.distance_mm
                    )
            
            self.gui.show(display)
            
            # í‚¤ ì²˜ë¦¬
            key = self.gui.wait_key(1)
            if key == ord('q'):
                break
            elif key == ord('d'):
                self.gui.show_depth = not self.gui.show_depth
            elif key == ord('z'):
                self.gui.show_zones = not self.gui.show_zones
            elif key == ord('t'):
                self.gui.show_tracks = not self.gui.show_tracks
            elif key == ord('s'):
                self._save_screenshot(display)
        
        self._cleanup()
    
    def _process_alerts(self, obstacles):
        """ê²½ê³  ì²˜ë¦¬"""
        
        for obs in obstacles:
            if obs.danger_level.value >= DangerLevel.WARNING.value:
                self.alert_system.trigger_alert(
                    obs.danger_level.name,
                    obs.distance_mm,
                    f"obstacle_{obs.id}"
                )
    
    def _save_screenshot(self, image):
        """ìŠ¤í¬ë¦°ìƒ· ì €ì¥"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"screenshots/obstacle_{timestamp}.png"
        cv2.imwrite(filename, image)
        print(f"ğŸ“¸ ìŠ¤í¬ë¦°ìƒ· ì €ì¥: {filename}")
    
    def _cleanup(self):
        """ì •ë¦¬"""
        self.camera.release()
        self.gui.close()
        print("\nì‹œìŠ¤í…œ ì¢…ë£Œ")


def main():
    parser = argparse.ArgumentParser(description='ì¥ì• ë¬¼ ê°ì§€ ì‹œìŠ¤í…œ')
    parser.add_argument('--config', default='config/detection_config.yaml')
    args = parser.parse_args()
    
    system = ObstacleDetectionSystem(args.config)
    system.run()


if __name__ == "__main__":
    main()
```

### 9.2 ì„¤ì • íŒŒì¼

```yaml
# config/detection_config.yaml

calibration_file: "config/stereo_params.yaml"

camera:
  left_id: 0
  right_id: 2
  width: 1280
  height: 720
  fps: 30

stereo:
  num_disparities: 128
  block_size: 5
  use_wls: true

detection:
  distance_thresholds:
    critical: 500    # 0.5m
    danger: 1000     # 1m
    warning: 2000    # 2m
    caution: 3000    # 3m
  min_distance: 200
  max_distance: 5000
  min_obstacle_area: 500
  ground_removal: true

tracking:
  max_lost_frames: 10
  iou_threshold: 0.3

alert:
  enabled: true
  visual: true
  audio: false
  min_interval_ms: 500
```

---

## 10. ì„±ëŠ¥ ìµœì í™”

### 10.1 ìµœì í™” íŒ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ì„±ëŠ¥ ìµœì í™” ê°€ì´ë“œ                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  ğŸ“¹ ì…ë ¥ ìµœì í™”                                              â”‚
â”‚    - í•´ìƒë„ ê°ì†Œ: 1280x720 â†’ 640x480                        â”‚
â”‚    - ROI ì²˜ë¦¬: ì „ì²´ í”„ë ˆì„ ëŒ€ì‹  ê´€ì‹¬ ì˜ì—­ë§Œ                   â”‚
â”‚                                                             â”‚
â”‚  ğŸ”§ ìŠ¤í…Œë ˆì˜¤ ìµœì í™”                                          â”‚
â”‚    - numDisparities ê°ì†Œ: 128 â†’ 64                         â”‚
â”‚    - blockSize ì¦ê°€: 5 â†’ 7 (ë…¸ì´ì¦ˆ ê°ì†Œ)                    â”‚
â”‚    - MODE_SGBM_3WAY ì‚¬ìš©                                    â”‚
â”‚                                                             â”‚
â”‚  ğŸ¯ ê°ì§€ ìµœì í™”                                              â”‚
â”‚    - min_obstacle_area ì¦ê°€: ì‘ì€ ë…¸ì´ì¦ˆ ë¬´ì‹œ               â”‚
â”‚    - í”„ë ˆì„ ìŠ¤í‚µ: 2-3 í”„ë ˆì„ë§ˆë‹¤ ê°ì§€                        â”‚
â”‚                                                             â”‚
â”‚  ğŸ’¾ ë©”ëª¨ë¦¬ ìµœì í™”                                            â”‚
â”‚    - numpy ë°°ì—´ ì¬ì‚¬ìš©                                       â”‚
â”‚    - ë¶ˆí•„ìš”í•œ ë³µì‚¬ ìµœì†Œí™”                                    â”‚
â”‚                                                             â”‚
â”‚  ğŸš€ ë³‘ë ¬ ì²˜ë¦¬                                                â”‚
â”‚    - ë©€í‹°ìŠ¤ë ˆë”©: ìº¡ì²˜/ì²˜ë¦¬ ë¶„ë¦¬                              â”‚
â”‚    - GPU: OpenCV CUDA ë˜ëŠ” VPI                             â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ í•™ìŠµ ì²´í¬ë¦¬ìŠ¤íŠ¸

### êµ¬í˜„ ì™„ë£Œ

- [ ] ê¹Šì´ ê¸°ë°˜ ì¥ì• ë¬¼ ê°ì§€
- [ ] ìœ„í—˜ ì˜ì—­ ë¶„ë¥˜ (5ë‹¨ê³„)
- [ ] ê°ì§€ ì˜ì—­ ê´€ë¦¬
- [ ] ê²½ê³  ì‹œìŠ¤í…œ (ì‹œê°/ì²­ê°)
- [ ] ê°ì²´ ì¶”ì 
- [ ] GUI êµ¬í˜„
- [ ] ë¯¸ë‹ˆë§µ (íƒ‘ë·°)

### í…ŒìŠ¤íŠ¸ ì™„ë£Œ

- [ ] ë‹¤ì–‘í•œ ê±°ë¦¬ì—ì„œ ê°ì§€ í…ŒìŠ¤íŠ¸
- [ ] ë‹¤ì¤‘ ì¥ì• ë¬¼ ê°ì§€
- [ ] ì¶”ì  ì •í™•ë„ í™•ì¸
- [ ] ê²½ê³  ì‹œìŠ¤í…œ ë™ì‘ í™•ì¸
- [ ] ì„±ëŠ¥ (FPS) í™•ì¸

---

## â¡ï¸ ë‹¤ìŒ í”„ë¡œì íŠ¸

**[Project 03: 3D ìŠ¤ìºë„ˆ](../Project_03_3D_Scanner/README.md)**

ë‹¤ìŒ í”„ë¡œì íŠ¸ì—ì„œëŠ”:
- ë‹¤ì¤‘ ì‹œì  3D ìŠ¤ìºë‹
- í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ì •í•©
- ë©”ì‰¬ ìƒì„±
- STL/OBJ ì¶œë ¥

ì„ êµ¬í˜„í•©ë‹ˆë‹¤.

---

## ğŸ“„ ë¼ì´ì„ ìŠ¤

MIT License - ììœ ë¡­ê²Œ ì‚¬ìš©, ìˆ˜ì •, ë°°í¬ ê°€ëŠ¥
